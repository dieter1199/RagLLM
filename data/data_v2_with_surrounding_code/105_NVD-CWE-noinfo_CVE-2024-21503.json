{
    "cve_id": "CVE-2024-21503",
    "cve_description": "Versions of the package black before 24.3.0 are vulnerable to Regular Expression Denial of Service (ReDoS) via the lines_with_leading_tabs_expanded function in the strings.py file. An attacker could exploit this vulnerability by crafting a malicious input that causes a denial of service.\r\rExploiting this vulnerability is possible when running Black on untrusted input, or if you habitually put thousands of leading tab characters in your docstrings.",
    "cve_publish_date": "2024-03-19T05:15Z",
    "cwe_id": "NVD-CWE-noinfo",
    "cwe_name": "Insufficient Information",
    "cwe_description": "There is insufficient information about the issue to classify it; details are unkown or unspecified.",
    "commit_message": "Fix catastrophic performance in lines_with_leading_tabs_expanded() (#4278)",
    "type_of_change": "Modification",
    "changes": [
        {
            "filename_of_changes": "strings.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "6",
            "number_of_lines_deleted_vulnerable_to_cve": "12",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 6: import sys",
                "// Line 7: from functools import lru_cache",
                "// Line 8: from typing import Final, List, Match, Pattern",
                "// Line 9: ",
                "// Line 10: from black._width_table import WIDTH_TABLE",
                "// Line 11: from blib2to3.pytree import Leaf",
                "// Line 12: ",
                "// Line 13: STRING_PREFIX_CHARS: Final = \"furbFURB\"  # All possible string prefix characters.",
                "// Line 14: STRING_PREFIX_RE: Final = re.compile(",
                "// Line 15:     r\"^([\" + STRING_PREFIX_CHARS + r\"]*)(.*)$\", re.DOTALL",
                "// vulnerable line: 16: )",
                "// Line 17: FIRST_NON_WHITESPACE_RE: Final = re.compile(r\"\\s*    +\\s*(\\S)\")",
                "// Line 18: UNICODE_ESCAPE_RE: Final = re.compile(",
                "// Line 19:     r\"(?P<backslashes>\\+)(?P<body>\"",
                "// Line 20:     r\"(u(?P<u>[a-fA-F0-9]{4}))\"  # Character with 16-bit hex value xxxx",
                "// Line 21:     r\"|(U(?P<U>[a-fA-F0-9]{8}))\"  # Character with 32-bit hex value xxxxxxxx",
                "// Line 22:     r\"|(x(?P<x>[a-fA-F0-9]{2}))\"  # Character with hex value hh",
                "// Line 23:     r\"|(N\\{(?P<N>[a-zA-Z0-9 \\-]{2,})\\})\"  # Character named name in the Unicode database",
                "// Line 24:     r\")\",",
                "// Line 25:     re.VERBOSE,",
                "// vulnerable line: 26: )",
                "// Line 27: ",
                "// Line 28: ",
                "// Line 29: def sub_twice(regex: Pattern[str], replacement: str, original: str) -> str:",
                "// Line 30:     \"\"\"Replace `regex` with `replacement` twice on `original`.",
                "// Line 31: ",
                "// Line 32:     This is used by string normalization to perform replaces on",
                "// Line 33:     overlapping matches.",
                "// Line 34:     \"\"\"",
                "// Line 35:     return regex.sub(replacement, regex.sub(replacement, original))",
                "// Line 36: ",
                "// Line 44:     return raw_string[:3] in {'\"\"\"', \"'''\"}",
                "// Line 45: ",
                "// Line 46: ",
                "// Line 47: def lines_with_leading_tabs_expanded(s: str) -> List[str]:",
                "// Line 48:     \"\"\"",
                "// Line 49:     Splits string into lines and expands only leading tabs (following the normal",
                "// Line 50:     Python rules)",
                "// Line 51:     \"\"\"",
                "// Line 52:     lines = []",
                "// Line 53:     for line in s.splitlines():",
                "// vulnerable line: 54: # Find the index of the first non-whitespace character after a string of",
                "// vulnerable line: 55: # whitespace that includes at least one tab",
                "// vulnerable line: 56: match = FIRST_NON_WHITESPACE_RE.match(line)",
                "// vulnerable line: 57: if match:",
                "// vulnerable line: 58: first_non_whitespace_idx = match.start(1)",
                "// Line 59: ",
                "// vulnerable line: 60: lines.append(",
                "// vulnerable line: 61: line[:first_non_whitespace_idx].expandtabs()",
                "// vulnerable line: 62: + line[first_non_whitespace_idx:]",
                "// vulnerable line: 63: )",
                "// vulnerable line: 64: else:",
                "// Line 65:             lines.append(line)",
                "// Line 66:     if s.endswith(\"",
                "// Line 67: \"):",
                "// Line 68:         lines.append(\"\")",
                "// Line 69:     return lines",
                "// Line 70: ",
                "// Line 71: ",
                "// Line 72: def fix_docstring(docstring: str, prefix: str) -> str:",
                "// Line 73:     # https://www.python.org/dev/peps/pep-0257/#handling-docstring-indentation",
                "// Line 74:     if not docstring:",
                "// Line 81:         if stripped:",
                "// Line 82:             indent = min(indent, len(line) - len(stripped))",
                "// Line 83:     # Remove indentation (first line is special):",
                "// Line 84:     trimmed = [lines[0].strip()]",
                "// Line 85:     if indent < sys.maxsize:",
                "// Line 86:         last_line_idx = len(lines) - 2",
                "// Line 87:         for i, line in enumerate(lines[1:]):",
                "// Line 88:             stripped_line = line[indent:].rstrip()",
                "// Line 89:             if stripped_line or i == last_line_idx:",
                "// Line 90:                 trimmed.append(prefix + stripped_line)",
                "// vulnerable line: 91: else:",
                "// Line 92:                 trimmed.append(\"\")",
                "// Line 93:     return \"",
                "// Line 94: \".join(trimmed)",
                "// Line 95: ",
                "// Line 96: ",
                "// Line 97: def get_string_prefix(string: str) -> str:",
                "// Line 98:     \"\"\"",
                "// Line 99:     Pre-conditions:",
                "// Line 100:         * assert_is_leaf_string(@string)",
                "// Line 101: ",
                "// Line 126:         * @string ends with a quote character (' or \").",
                "// Line 127: ",
                "// Line 128:     Raises:",
                "// Line 129:         AssertionError(...) if the pre-conditions listed above are not",
                "// Line 130:         satisfied.",
                "// Line 131:     \"\"\"",
                "// Line 132:     dquote_idx = string.find('\"')",
                "// Line 133:     squote_idx = string.find(\"'\")",
                "// Line 134:     if -1 in [dquote_idx, squote_idx]:",
                "// Line 135:         quote_idx = max(dquote_idx, squote_idx)",
                "// vulnerable line: 136: else:",
                "// Line 137:         quote_idx = min(squote_idx, dquote_idx)",
                "// Line 138: ",
                "// Line 139:     assert (",
                "// Line 140:         0 <= quote_idx < len(string) - 1",
                "// Line 141:     ), f\"{string!r} is missing a starting quote character (' or \").\"",
                "// Line 142:     assert string[-1] in (",
                "// Line 143:         \"'\",",
                "// Line 144:         '\"',",
                "// Line 145:     ), f\"{string!r} is missing an ending quote character (' or \").\"",
                "// Line 146:     assert set(string[:quote_idx]).issubset(",
                "// Line 151: def normalize_string_prefix(s: str) -> str:",
                "// Line 152:     \"\"\"Make all string prefixes lowercase.\"\"\"",
                "// Line 153:     match = STRING_PREFIX_RE.match(s)",
                "// Line 154:     assert match is not None, f\"failed to match string {s!r}\"",
                "// Line 155:     orig_prefix = match.group(1)",
                "// Line 156:     new_prefix = (",
                "// Line 157:         orig_prefix.replace(\"F\", \"f\")",
                "// Line 158:         .replace(\"B\", \"b\")",
                "// Line 159:         .replace(\"U\", \"\")",
                "// Line 160:         .replace(\"u\", \"\")",
                "// vulnerable line: 161: )",
                "// Line 162: ",
                "// Line 163:     # Python syntax guarantees max 2 prefixes and that one of them is \"r\"",
                "// Line 164:     if len(new_prefix) == 2 and \"r\" != new_prefix[0].lower():",
                "// Line 165:         new_prefix = new_prefix[::-1]",
                "// Line 166:     return f\"{new_prefix}{match.group(2)}\"",
                "// Line 167: ",
                "// Line 168: ",
                "// Line 169: # Re(gex) does actually cache patterns internally but this still improves",
                "// Line 170: # performance on a long list literal of strings by 5-9% since lru_cache's",
                "// Line 171: # caching overhead is much lower.",
                "// Line 183:     value = s.lstrip(STRING_PREFIX_CHARS)",
                "// Line 184:     if value[:3] == '\"\"\"':",
                "// Line 185:         return s",
                "// Line 186: ",
                "// Line 187:     elif value[:3] == \"'''\":",
                "// Line 188:         orig_quote = \"'''\"",
                "// Line 189:         new_quote = '\"\"\"'",
                "// Line 190:     elif value[0] == '\"':",
                "// Line 191:         orig_quote = '\"'",
                "// Line 192:         new_quote = \"'\"",
                "// vulnerable line: 193: else:",
                "// Line 194:         orig_quote = \"'\"",
                "// Line 195:         new_quote = '\"'",
                "// Line 196:     first_quote_pos = s.find(orig_quote)",
                "// Line 197:     if first_quote_pos == -1:",
                "// Line 198:         return s  # There's an internal error",
                "// Line 199: ",
                "// Line 200:     prefix = s[:first_quote_pos]",
                "// Line 201:     unescaped_new_quote = _cached_compile(rf\"(([^\\]|^)(\\)*){new_quote}\")",
                "// Line 202:     escaped_new_quote = _cached_compile(rf\"([^\\]|^)\\((?:\\)*){new_quote}\")",
                "// Line 203:     escaped_orig_quote = _cached_compile(rf\"([^\\]|^)\\((?:\\)*){orig_quote}\")",
                "// Line 204:     body = s[first_quote_pos + len(orig_quote) : -len(orig_quote)]",
                "// Line 205:     if \"r\" in prefix.casefold():",
                "// Line 206:         if unescaped_new_quote.search(body):",
                "// Line 207:             # There's at least one unescaped new_quote in this raw string",
                "// Line 208:             # so converting is impossible",
                "// Line 209:             return s",
                "// Line 210: ",
                "// Line 211:         # Do not introduce or remove backslashes in raw strings",
                "// Line 212:         new_body = body",
                "// vulnerable line: 213: else:",
                "// Line 214:         # remove unnecessary escapes",
                "// Line 215:         new_body = sub_twice(escaped_new_quote, rf\"\u0001\u0002{new_quote}\", body)",
                "// Line 216:         if body != new_body:",
                "// Line 217:             # Consider the string without unnecessary escapes as the original",
                "// Line 218:             body = new_body",
                "// Line 219:             s = f\"{prefix}{orig_quote}{body}{orig_quote}\"",
                "// Line 220:         new_body = sub_twice(escaped_orig_quote, rf\"\u0001\u0002{orig_quote}\", new_body)",
                "// Line 221:         new_body = sub_twice(unescaped_new_quote, rf\"\u0001\\{new_quote}\", new_body)",
                "// Line 222:     if \"f\" in prefix.casefold():",
                "// Line 223:         matches = re.findall(",
                "// Line 224:             r\"\"\"",
                "// Line 225:             (?:(?<!\\{)|^)\\{  # start of the string or a non-{ followed by a single {",
                "// Line 226:                 ([^{].*?)  # contents of the brackets except if begins with {{",
                "// Line 227:             \\}(?:(?!\\})|$)  # A } followed by end of the string or a non-}",
                "// Line 228:             \"\"\",",
                "// Line 229:             new_body,",
                "// Line 230:             re.VERBOSE,",
                "// vulnerable line: 231: )",
                "// Line 232:         for m in matches:",
                "// Line 233:             if \"\" in str(m):",
                "// Line 234:                 # Do not introduce backslashes in interpolated expressions",
                "// Line 235:                 return s",
                "// Line 236: ",
                "// Line 237:     if new_quote == '\"\"\"' and new_body[-1:] == '\"':",
                "// Line 238:         # edge case:",
                "// Line 239:         new_body = new_body[:-1] + '\"'",
                "// Line 240:     orig_escape_count = body.count(\"\")",
                "// Line 241:     new_escape_count = new_body.count(\"\")",
                "// Line 264: ",
                "// Line 265:         if groups[\"u\"]:",
                "// Line 266:             # ",
                "// Line 267:             return back_slashes + \"u\" + groups[\"u\"].lower()",
                "// Line 268:         elif groups[\"U\"]:",
                "// Line 269:             # ",
                "// Line 270:             return back_slashes + \"U\" + groups[\"U\"].lower()",
                "// Line 271:         elif groups[\"x\"]:",
                "// Line 272:             # ",
                "// Line 273:             return back_slashes + \"x\" + groups[\"x\"].lower()",
                "// vulnerable line: 274: else:",
                "// Line 275:             assert groups[\"N\"], f\"Unexpected match: {m}\"",
                "// Line 276:             # }",
                "// Line 277:             return back_slashes + \"N{\" + groups[\"N\"].upper() + \"}\"",
                "// Line 278: ",
                "// Line 279:     leaf.value = re.sub(UNICODE_ESCAPE_RE, replace, text)",
                "// Line 280: ",
                "// Line 281: ",
                "// Line 282: @lru_cache(maxsize=4096)",
                "// Line 283: def char_width(char: str) -> int:",
                "// Line 284:     \"\"\"Return the width of a single character as it would be displayed in a",
                "// Line 291:     codepoint = ord(char)",
                "// Line 292:     highest = len(table) - 1",
                "// Line 293:     lowest = 0",
                "// Line 294:     idx = highest // 2",
                "// Line 295:     while True:",
                "// Line 296:         start_codepoint, end_codepoint, width = table[idx]",
                "// Line 297:         if codepoint < start_codepoint:",
                "// Line 298:             highest = idx - 1",
                "// Line 299:         elif codepoint > end_codepoint:",
                "// Line 300:             lowest = idx + 1",
                "// vulnerable line: 301: else:",
                "// Line 302:             return 0 if width < 0 else width",
                "// Line 303:         if highest < lowest:",
                "// Line 304:             break",
                "// Line 305:         idx = (highest + lowest) // 2",
                "// Line 306:     return 1",
                "// Line 307: ",
                "// Line 308: ",
                "// Line 309: def str_width(line_str: str) -> int:",
                "// Line 310:     \"\"\"Return the width of `line_str` as it would be displayed in a terminal",
                "// Line 311:     or editor (which respects Unicode East Asian Width)."
            ]
        },
        {
            "filename_of_changes": "test_black.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "12",
            "number_of_lines_deleted_vulnerable_to_cve": "0",
            "Code_with_highlighted_vulnerability_lines": []
        }
    ]
}