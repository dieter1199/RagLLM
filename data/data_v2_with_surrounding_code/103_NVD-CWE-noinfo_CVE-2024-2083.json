{
    "cve_id": "CVE-2024-2083",
    "cve_description": "A directory traversal vulnerability exists in the zenml-io/zenml repository, specifically within the /api/v1/steps endpoint. Attackers can exploit this vulnerability by manipulating the 'logs' URI path in the request to fetch arbitrary file content, bypassing intended access restrictions. The vulnerability arises due to the lack of validation for directory traversal patterns, allowing attackers to access files outside of the restricted directory.",
    "cve_publish_date": "2024-04-16T00:15Z",
    "cwe_id": "NVD-CWE-noinfo",
    "cwe_name": "Insufficient Information",
    "cwe_description": "There is insufficient information about the issue to classify it; details are unkown or unspecified.",
    "commit_message": "Improve Artifact Store isolation (#2490)\n\n* dir traversal issue\r\n\r\n* Auto-update of Starter template\r\n\r\n* Auto-update of NLP template\r\n\r\n* reroute artifacts and logs via AS\r\n\r\n* reroute materializers via AS\r\n\r\n* simplify to one deco\r\n\r\n* fix materializer tests\r\n\r\n* allow local download\r\n\r\n* Auto-update of E2E template\r\n\r\n* fix test issues\r\n\r\n* rework based on comments\r\n\r\n* fix bugs\r\n\r\n* lint\r\n\r\n* Candidate (#2493)\r\n\r\nCo-authored-by: Stefan Nica <stefan@zenml.io>\r\n\r\n* darglint\r\n\r\n---------\r\n\r\nCo-authored-by: GitHub Actions <actions@github.com>\r\nCo-authored-by: Stefan Nica <stefan@zenml.io>",
    "type_of_change": "Modification",
    "changes": [
        {
            "filename_of_changes": "base_materializer.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "2",
            "number_of_lines_deleted_vulnerable_to_cve": "1",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 150:         \"\"\"Save visualizations of the given data.",
                "// Line 151: ",
                "// Line 152:         If this method is not overridden, no visualizations will be saved.",
                "// Line 153: ",
                "// Line 154:         When overriding this method, make sure to save all visualizations to",
                "// Line 155:         files within `self.uri`.",
                "// Line 156: ",
                "// Line 157:         Example:",
                "// Line 158:         ```",
                "// Line 159:         visualization_uri = os.path.join(self.uri, \"visualization.html\")",
                "// vulnerable line: 160: with fileio.open(visualization_uri, \"w\") as f:",
                "// Line 161:             f.write(\"<html><body>data</body></html>\")",
                "// Line 162: ",
                "// Line 163:         visualization_uri_2 = os.path.join(self.uri, \"visualization.png\")",
                "// Line 164:         data.save_as_png(visualization_uri_2)",
                "// Line 165: ",
                "// Line 166:         return {",
                "// Line 167:             visualization_uri: ArtifactVisualizationType.HTML,",
                "// Line 168:             visualization_uri_2: ArtifactVisualizationType.IMAGE",
                "// Line 169:         }",
                "// Line 170:         ```"
            ]
        },
        {
            "filename_of_changes": "built_in_materializer.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "15",
            "number_of_lines_deleted_vulnerable_to_cve": "11",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 20:     ClassVar,",
                "// Line 21:     Dict,",
                "// Line 22:     Iterable,",
                "// Line 23:     List,",
                "// Line 24:     Tuple,",
                "// Line 25:     Type,",
                "// Line 26:     Union,",
                "// Line 27: )",
                "// Line 28: ",
                "// Line 29: from zenml.enums import ArtifactType",
                "// vulnerable line: 30: from zenml.io import fileio",
                "// Line 31: from zenml.logger import get_logger",
                "// Line 32: from zenml.materializers.base_materializer import BaseMaterializer",
                "// Line 33: from zenml.materializers.materializer_registry import materializer_registry",
                "// Line 34: from zenml.utils import source_utils, yaml_utils",
                "// Line 35: ",
                "// Line 36: if TYPE_CHECKING:",
                "// Line 37:     from zenml.metadata.metadata_types import MetadataType",
                "// Line 38: ",
                "// Line 39: logger = get_logger(__name__)",
                "// Line 40: DEFAULT_FILENAME = \"data.json\"",
                "// Line 128: ",
                "// Line 129:     def load(self, data_type: Type[Any]) -> Any:",
                "// Line 130:         \"\"\"Reads a bytes object from file.",
                "// Line 131: ",
                "// Line 132:         Args:",
                "// Line 133:             data_type: The type of the data to read.",
                "// Line 134: ",
                "// Line 135:         Returns:",
                "// Line 136:             The data read.",
                "// Line 137:         \"\"\"",
                "// vulnerable line: 138: with fileio.open(self.data_path, \"rb\") as file_:",
                "// Line 139:             return file_.read()",
                "// Line 140: ",
                "// Line 141:     def save(self, data: Any) -> None:",
                "// Line 142:         \"\"\"Save a bytes object to file.",
                "// Line 143: ",
                "// Line 144:         Args:",
                "// Line 145:             data: The data to store.",
                "// Line 146:         \"\"\"",
                "// vulnerable line: 147: with fileio.open(self.data_path, \"wb\") as file_:",
                "// Line 148:             file_.write(data)",
                "// Line 149: ",
                "// Line 150: ",
                "// Line 151: def _all_serializable(iterable: Iterable[Any]) -> bool:",
                "// Line 152:     \"\"\"For an iterable, check whether all of its elements are JSON-serializable.",
                "// Line 153: ",
                "// Line 154:     Args:",
                "// Line 155:         iterable (Iterable): The iterable to check.",
                "// Line 156: ",
                "// Line 157:     Returns:",
                "// Line 276:         Args:",
                "// Line 277:             data_type: The type of the data to read.",
                "// Line 278: ",
                "// Line 279:         Returns:",
                "// Line 280:             The data read.",
                "// Line 281: ",
                "// Line 282:         Raises:",
                "// Line 283:             RuntimeError: If the data was not found.",
                "// Line 284:         \"\"\"",
                "// Line 285:         # If the data was not serialized, there must be metadata present.",
                "// vulnerable line: 286: if not fileio.exists(self.data_path) and not fileio.exists(",
                "// vulnerable line: 287: self.metadata_path",
                "// vulnerable line: 288: ):",
                "// Line 289:             raise RuntimeError(",
                "// Line 290:                 f\"Materialization of type {data_type} failed. Expected either\"",
                "// Line 291:                 f\"{self.data_path} or {self.metadata_path} to exist.\"",
                "// Line 292:             )",
                "// Line 293: ",
                "// Line 294:         # If the data was serialized as JSON, deserialize it.",
                "// vulnerable line: 295: if fileio.exists(self.data_path):",
                "// Line 296:             outputs = yaml_utils.read_json(self.data_path)",
                "// Line 297: ",
                "// Line 298:         # Otherwise, use the metadata to reconstruct the data as a list.",
                "// Line 299:         else:",
                "// Line 300:             metadata = yaml_utils.read_json(self.metadata_path)",
                "// Line 301:             outputs = []",
                "// Line 302: ",
                "// Line 303:             # Backwards compatibility for zenml <= 0.37.0",
                "// Line 304:             if isinstance(metadata, dict):",
                "// Line 305:                 for path_, type_str in zip(",
                "// Line 306:                     metadata[\"paths\"], metadata[\"types\"]",
                "// vulnerable line: 307: ):",
                "// Line 308:                     type_ = find_type_by_str(type_str)",
                "// Line 309:                     materializer_class = materializer_registry[type_]",
                "// Line 310:                     materializer = materializer_class(uri=path_)",
                "// Line 311:                     element = materializer.load(type_)",
                "// Line 312:                     outputs.append(element)",
                "// Line 313: ",
                "// Line 314:             # New format for zenml > 0.37.0",
                "// Line 315:             elif isinstance(metadata, list):",
                "// Line 316:                 for entry in metadata:",
                "// Line 317:                     path_ = entry[\"path\"]",
                "// Line 368:         if isinstance(data, dict):",
                "// Line 369:             data = [list(data.keys()), list(data.values())]",
                "// Line 370: ",
                "// Line 371:         # non-serializable list: Materialize each element into a subfolder.",
                "// Line 372:         # Get path, type, and corresponding materializer for each element.",
                "// Line 373:         metadata: List[Dict[str, str]] = []",
                "// Line 374:         materializers: List[BaseMaterializer] = []",
                "// Line 375:         try:",
                "// Line 376:             for i, element in enumerate(data):",
                "// Line 377:                 element_path = os.path.join(self.uri, str(i))",
                "// vulnerable line: 378: fileio.mkdir(element_path)",
                "// Line 379:                 type_ = type(element)",
                "// Line 380:                 materializer_class = materializer_registry[type_]",
                "// Line 381:                 materializer = materializer_class(uri=element_path)",
                "// Line 382:                 materializers.append(materializer)",
                "// Line 383:                 metadata.append(",
                "// Line 384:                     {",
                "// Line 385:                         \"path\": element_path,",
                "// Line 386:                         \"type\": source_utils.resolve(type_).import_path,",
                "// Line 387:                         \"materializer\": source_utils.resolve(",
                "// Line 388:                             materializer_class",
                "// Line 391:                 )",
                "// Line 392:             # Write metadata as JSON.",
                "// Line 393:             yaml_utils.write_json(self.metadata_path, metadata)",
                "// Line 394:             # Materialize each element.",
                "// Line 395:             for element, materializer in zip(data, materializers):",
                "// Line 396:                 materializer.validate_type_compatibility(type(element))",
                "// Line 397:                 materializer.save(element)",
                "// Line 398:         # If an error occurs, delete all created files.",
                "// Line 399:         except Exception as e:",
                "// Line 400:             # Delete metadata",
                "// vulnerable line: 401: if fileio.exists(self.metadata_path):",
                "// vulnerable line: 402: fileio.remove(self.metadata_path)",
                "// Line 403:             # Delete all elements that were already saved.",
                "// Line 404:             for entry in metadata:",
                "// vulnerable line: 405: fileio.rmtree(entry[\"path\"])",
                "// Line 406:             raise e",
                "// Line 407: ",
                "// Line 408:     def extract_metadata(self, data: Any) -> Dict[str, \"MetadataType\"]:",
                "// Line 409:         \"\"\"Extract metadata from the given built-in container object.",
                "// Line 410: ",
                "// Line 411:         Args:",
                "// Line 412:             data: The built-in container object to extract metadata from.",
                "// Line 413: ",
                "// Line 414:         Returns:",
                "// Line 415:             The extracted metadata as a dictionary."
            ]
        },
        {
            "filename_of_changes": "cloudpickle_materializer.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "5",
            "number_of_lines_deleted_vulnerable_to_cve": "3",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 13: #  permissions and limitations under the License.",
                "// Line 14: \"\"\"Implementation of ZenML's cloudpickle materializer.\"\"\"",
                "// Line 15: ",
                "// Line 16: import os",
                "// Line 17: from typing import Any, ClassVar, Tuple, Type",
                "// Line 18: ",
                "// Line 19: import cloudpickle",
                "// Line 20: ",
                "// Line 21: from zenml.enums import ArtifactType",
                "// Line 22: from zenml.environment import Environment",
                "// vulnerable line: 23: from zenml.io import fileio",
                "// Line 24: from zenml.logger import get_logger",
                "// Line 25: from zenml.materializers.base_materializer import BaseMaterializer",
                "// Line 26: from zenml.utils.io_utils import (",
                "// Line 27:     read_file_contents_as_string,",
                "// Line 28:     write_file_contents_as_string,",
                "// Line 29: )",
                "// Line 30: ",
                "// Line 31: logger = get_logger(__name__)",
                "// Line 32: ",
                "// Line 33: DEFAULT_FILENAME = \"artifact.pkl\"",
                "// Line 65:             logger.warning(",
                "// Line 66:                 f\"Your artifact was materialized under Python version \"",
                "// Line 67:                 f\"'{source_python_version}' but you are currently using \"",
                "// Line 68:                 f\"'{current_python_version}'. This might cause unexpected \"",
                "// Line 69:                 \"behavior since pickle is not reproducible across Python \"",
                "// Line 70:                 \"versions. Attempting to load anyway...\"",
                "// Line 71:             )",
                "// Line 72: ",
                "// Line 73:         # load data",
                "// Line 74:         filepath = os.path.join(self.uri, DEFAULT_FILENAME)",
                "// vulnerable line: 75: with fileio.open(filepath, \"rb\") as fid:",
                "// Line 76:             data = cloudpickle.load(fid)",
                "// Line 77:         return data",
                "// Line 78: ",
                "// Line 79:     def _load_python_version(self) -> str:",
                "// Line 80:         \"\"\"Loads the Python version that was used to materialize the artifact.",
                "// Line 81: ",
                "// Line 82:         Returns:",
                "// Line 83:             The Python version that was used to materialize the artifact.",
                "// Line 84:         \"\"\"",
                "// Line 85:         filepath = os.path.join(self.uri, DEFAULT_PYTHON_VERSION_FILENAME)",
                "// Line 104:                 \"Python version. Please consider implementing a custom \"",
                "// Line 105:                 f\"materializer for type `{type(data)}` according to the \"",
                "// Line 106:                 \"instructions at https://docs.zenml.io/user-guide/advanced-guide/artifact-management/handle-custom-data-types\"",
                "// Line 107:             )",
                "// Line 108: ",
                "// Line 109:         # save python version for validation on loading",
                "// Line 110:         self._save_python_version()",
                "// Line 111: ",
                "// Line 112:         # save data",
                "// Line 113:         filepath = os.path.join(self.uri, DEFAULT_FILENAME)",
                "// vulnerable line: 114: with fileio.open(filepath, \"wb\") as fid:",
                "// Line 115:             cloudpickle.dump(data, fid)",
                "// Line 116: ",
                "// Line 117:     def _save_python_version(self) -> None:",
                "// Line 118:         \"\"\"Saves the Python version used to materialize the artifact.\"\"\"",
                "// Line 119:         filepath = os.path.join(self.uri, DEFAULT_PYTHON_VERSION_FILENAME)",
                "// Line 120:         current_python_version = Environment().python_version()",
                "// Line 121:         write_file_contents_as_string(filepath, current_python_version)"
            ]
        },
        {
            "filename_of_changes": "numpy_materializer.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "14",
            "number_of_lines_deleted_vulnerable_to_cve": "8",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 13: #  permissions and limitations under the License.",
                "// Line 14: \"\"\"Implementation of the ZenML NumPy materializer.\"\"\"",
                "// Line 15: ",
                "// Line 16: import os",
                "// Line 17: from collections import Counter",
                "// Line 18: from typing import TYPE_CHECKING, Any, ClassVar, Dict, Tuple, Type",
                "// Line 19: ",
                "// Line 20: import numpy as np",
                "// Line 21: ",
                "// Line 22: from zenml.enums import ArtifactType, VisualizationType",
                "// vulnerable line: 23: from zenml.io import fileio",
                "// Line 24: from zenml.logger import get_logger",
                "// Line 25: from zenml.materializers.base_materializer import BaseMaterializer",
                "// Line 26: from zenml.metadata.metadata_types import DType, MetadataType",
                "// Line 27: ",
                "// Line 28: if TYPE_CHECKING:",
                "// Line 29:     from numpy.typing import NDArray",
                "// Line 30: ",
                "// Line 31: logger = get_logger(__name__)",
                "// Line 32: ",
                "// Line 33: ",
                "// Line 52: ",
                "// Line 53: ",
                "// Line 54:         Raises:",
                "// Line 55:             ImportError: If pyarrow is not installed.",
                "// Line 56: ",
                "// Line 57:         Returns:",
                "// Line 58:             The numpy array.",
                "// Line 59:         \"\"\"",
                "// Line 60:         numpy_file = os.path.join(self.uri, NUMPY_FILENAME)",
                "// Line 61: ",
                "// vulnerable line: 62: if fileio.exists(numpy_file):",
                "// vulnerable line: 63: with fileio.open(numpy_file, \"rb\") as f:",
                "// Line 64:                 return np.load(f, allow_pickle=True)",
                "// vulnerable line: 65: elif fileio.exists(os.path.join(self.uri, DATA_FILENAME)):",
                "// Line 66:             logger.warning(",
                "// Line 67:                 \"A legacy artifact was found. \"",
                "// Line 68:                 \"This artifact was created with an older version of \"",
                "// Line 69:                 \"ZenML. You can still use it, but it will be \"",
                "// Line 70:                 \"converted to the new format on the next materialization.\"",
                "// Line 71:             )",
                "// Line 72:             try:",
                "// Line 73:                 # Import old materializer dependencies",
                "// Line 74:                 import pyarrow as pa  # type: ignore",
                "// Line 75:                 import pyarrow.parquet as pq  # type: ignore",
                "// Line 76: ",
                "// Line 77:                 from zenml.utils import yaml_utils",
                "// Line 78: ",
                "// Line 79:                 # Read numpy array from parquet file",
                "// Line 80:                 shape_dict = yaml_utils.read_json(",
                "// Line 81:                     os.path.join(self.uri, SHAPE_FILENAME)",
                "// Line 82:                 )",
                "// Line 83:                 shape_tuple = tuple(shape_dict.values())",
                "// vulnerable line: 84: with fileio.open(",
                "// Line 85:                     os.path.join(self.uri, DATA_FILENAME), \"rb\"",
                "// Line 86:                 ) as f:",
                "// Line 87:                     input_stream = pa.input_stream(f)",
                "// Line 88:                     data = pq.read_table(input_stream)",
                "// Line 89:                 vals = getattr(data.to_pandas(), DATA_VAR).values",
                "// Line 90:                 return np.reshape(vals, shape_tuple)",
                "// Line 91:             except ImportError:",
                "// Line 92:                 raise ImportError(",
                "// Line 93:                     \"You have an old version of a `NumpyMaterializer` \",",
                "// Line 94:                     \"data artifact stored in the artifact store \",",
                "// Line 95:                     \"as a `.parquet` file, which requires `pyarrow` for reading. \",",
                "// Line 96:                     \"You can install `pyarrow` by running `pip install pyarrow`.\",",
                "// Line 97:                 )",
                "// Line 98: ",
                "// Line 99:     def save(self, arr: \"NDArray[Any]\") -> None:",
                "// Line 100:         \"\"\"Writes a np.ndarray to the artifact store as a `.npy` file.",
                "// Line 101: ",
                "// Line 102:         Args:",
                "// Line 103:             arr: The numpy array to write.",
                "// Line 104:         \"\"\"",
                "// vulnerable line: 105: with fileio.open(os.path.join(self.uri, NUMPY_FILENAME), \"wb\") as f:",
                "// Line 106:             np.save(f, arr)",
                "// Line 107: ",
                "// Line 108:     def save_visualizations(",
                "// Line 109:         self, arr: \"NDArray[Any]\"",
                "// Line 110:     ) -> Dict[str, VisualizationType]:",
                "// Line 111:         \"\"\"Saves visualizations for a numpy array.",
                "// Line 112: ",
                "// Line 113:         If the array is 1D, a histogram is saved. If the array is 2D or 3D with",
                "// Line 114:         3 or 4 channels, an image is saved.",
                "// Line 115: ",
                "// Line 149:     def _save_histogram(self, output_path: str, arr: \"NDArray[Any]\") -> None:",
                "// Line 150:         \"\"\"Saves a histogram of a numpy array.",
                "// Line 151: ",
                "// Line 152:         Args:",
                "// Line 153:             output_path: The path to save the histogram to.",
                "// Line 154:             arr: The numpy array of which to save the histogram.",
                "// Line 155:         \"\"\"",
                "// Line 156:         import matplotlib.pyplot as plt",
                "// Line 157: ",
                "// Line 158:         plt.hist(arr)",
                "// vulnerable line: 159: with fileio.open(output_path, \"wb\") as f:",
                "// Line 160:             plt.savefig(f)",
                "// Line 161:         plt.close()",
                "// Line 162: ",
                "// Line 163:     def _save_image(self, output_path: str, arr: \"NDArray[Any]\") -> None:",
                "// Line 164:         \"\"\"Saves a numpy array as an image.",
                "// Line 165: ",
                "// Line 166:         Args:",
                "// Line 167:             output_path: The path to save the image to.",
                "// Line 168:             arr: The numpy array to save.",
                "// Line 169:         \"\"\"",
                "// Line 170:         from matplotlib.image import imsave",
                "// Line 171: ",
                "// vulnerable line: 172: with fileio.open(output_path, \"wb\") as f:",
                "// Line 173:             imsave(f, arr)",
                "// Line 174: ",
                "// Line 175:     def extract_metadata(",
                "// Line 176:         self, arr: \"NDArray[Any]\"",
                "// Line 177:     ) -> Dict[str, \"MetadataType\"]:",
                "// Line 178:         \"\"\"Extract metadata from the given numpy array.",
                "// Line 179: ",
                "// Line 180:         Args:",
                "// Line 181:             arr: The numpy array to extract metadata from.",
                "// Line 182: "
            ]
        },
        {
            "filename_of_changes": "output_utils.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "7",
            "number_of_lines_deleted_vulnerable_to_cve": "5",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 10: #  distributed under the License is distributed on an \"AS IS\" BASIS,",
                "// Line 11: #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
                "// Line 12: #  or implied. See the License for the specific language governing",
                "// Line 13: #  permissions and limitations under the License.",
                "// Line 14: \"\"\"Utilities for outputs.\"\"\"",
                "// Line 15: ",
                "// Line 16: import os",
                "// Line 17: from typing import TYPE_CHECKING, Dict, Sequence",
                "// Line 18: from uuid import uuid4",
                "// Line 19: ",
                "// vulnerable line: 20: from zenml.io import fileio",
                "// Line 21: from zenml.logger import get_logger",
                "// Line 22: ",
                "// Line 23: if TYPE_CHECKING:",
                "// Line 24:     from zenml.artifact_stores import BaseArtifactStore",
                "// Line 25:     from zenml.config.step_configurations import Step",
                "// Line 26:     from zenml.models import StepRunResponse",
                "// Line 27:     from zenml.stack import Stack",
                "// Line 28: ",
                "// Line 29: ",
                "// Line 30: logger = get_logger(__name__)",
                "// Line 72:     Returns:",
                "// Line 73:         A dictionary mapping output names to artifact URIs.",
                "// Line 74:     \"\"\"",
                "// Line 75:     output_artifact_uris: Dict[str, str] = {}",
                "// Line 76:     for output_name in step.config.outputs.keys():",
                "// Line 77:         artifact_uri = generate_artifact_uri(",
                "// Line 78:             artifact_store=stack.artifact_store,",
                "// Line 79:             step_run=step_run,",
                "// Line 80:             output_name=output_name,",
                "// Line 81:         )",
                "// vulnerable line: 82: if fileio.exists(artifact_uri):",
                "// Line 83:             raise RuntimeError(\"Artifact already exists\")",
                "// vulnerable line: 84: fileio.makedirs(artifact_uri)",
                "// Line 85:         output_artifact_uris[output_name] = artifact_uri",
                "// Line 86:     return output_artifact_uris",
                "// Line 87: ",
                "// Line 88: ",
                "// Line 89: def remove_artifact_dirs(artifact_uris: Sequence[str]) -> None:",
                "// Line 90:     \"\"\"Removes the artifact directories.",
                "// Line 91: ",
                "// Line 92:     Args:",
                "// Line 93:         artifact_uris: URIs of the artifacts to remove the directories for.",
                "// Line 94:     \"\"\"",
                "// Line 95:     for artifact_uri in artifact_uris:",
                "// vulnerable line: 96: if fileio.isdir(artifact_uri):",
                "// vulnerable line: 97: fileio.rmtree(artifact_uri)"
            ]
        },
        {
            "filename_of_changes": "pandas_materializer.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "10",
            "number_of_lines_deleted_vulnerable_to_cve": "7",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 12: #  or implied. See the License for the specific language governing",
                "// Line 13: #  permissions and limitations under the License.",
                "// Line 14: \"\"\"Materializer for Pandas.\"\"\"",
                "// Line 15: ",
                "// Line 16: import os",
                "// Line 17: from typing import Any, ClassVar, Dict, Tuple, Type, Union",
                "// Line 18: ",
                "// Line 19: import pandas as pd",
                "// Line 20: ",
                "// Line 21: from zenml.enums import ArtifactType, VisualizationType",
                "// vulnerable line: 22: from zenml.io import fileio",
                "// Line 23: from zenml.logger import get_logger",
                "// Line 24: from zenml.materializers.base_materializer import BaseMaterializer",
                "// Line 25: from zenml.metadata.metadata_types import DType, MetadataType",
                "// Line 26: ",
                "// Line 27: logger = get_logger(__name__)",
                "// Line 28: ",
                "// Line 29: PARQUET_FILENAME = \"df.parquet.gzip\"",
                "// Line 30: COMPRESSION_TYPE = \"gzip\"",
                "// Line 31: ",
                "// Line 32: CSV_FILENAME = \"df.csv\"",
                "// Line 70: ",
                "// Line 71:         Args:",
                "// Line 72:             data_type: The type of the data to read.",
                "// Line 73: ",
                "// Line 74:         Raises:",
                "// Line 75:             ImportError: If pyarrow or fastparquet is not installed.",
                "// Line 76: ",
                "// Line 77:         Returns:",
                "// Line 78:             The pandas dataframe or series.",
                "// Line 79:         \"\"\"",
                "// vulnerable line: 80: if fileio.exists(self.parquet_path):",
                "// Line 81:             if self.pyarrow_exists:",
                "// vulnerable line: 82: with fileio.open(self.parquet_path, mode=\"rb\") as f:",
                "// Line 83:                     df = pd.read_parquet(f)",
                "// Line 84:             else:",
                "// Line 85:                 raise ImportError(",
                "// Line 86:                     \"You have an old version of a `PandasMaterializer` \"",
                "// Line 87:                     \"data artifact stored in the artifact store \"",
                "// Line 88:                     \"as a `.parquet` file, which requires `pyarrow` \"",
                "// Line 89:                     \"for reading, You can install `pyarrow` by running \"",
                "// Line 90:                     \"'`pip install pyarrow fastparquet`'.\"",
                "// Line 91:                 )",
                "// Line 92:         else:",
                "// vulnerable line: 93: with fileio.open(self.csv_path, mode=\"rb\") as f:",
                "// Line 94:                 df = pd.read_csv(f, index_col=0, parse_dates=True)",
                "// Line 95: ",
                "// Line 96:         # validate the type of the data.",
                "// Line 97:         def is_dataframe_or_series(",
                "// Line 98:             df: Union[pd.DataFrame, pd.Series],",
                "// Line 99:         ) -> Union[pd.DataFrame, pd.Series]:",
                "// Line 100:             \"\"\"Checks if the data is a `pd.DataFrame` or `pd.Series`.",
                "// Line 101: ",
                "// Line 102:             Args:",
                "// Line 103:                 df: The data to check.",
                "// Line 119:     def save(self, df: Union[pd.DataFrame, pd.Series]) -> None:",
                "// Line 120:         \"\"\"Writes a pandas dataframe or series to the specified filename.",
                "// Line 121: ",
                "// Line 122:         Args:",
                "// Line 123:             df: The pandas dataframe or series to write.",
                "// Line 124:         \"\"\"",
                "// Line 125:         if isinstance(df, pd.Series):",
                "// Line 126:             df = df.to_frame(name=\"series\")",
                "// Line 127: ",
                "// Line 128:         if self.pyarrow_exists:",
                "// vulnerable line: 129: with fileio.open(self.parquet_path, mode=\"wb\") as f:",
                "// Line 130:                 df.to_parquet(f, compression=COMPRESSION_TYPE)",
                "// Line 131:         else:",
                "// vulnerable line: 132: with fileio.open(self.csv_path, mode=\"wb\") as f:",
                "// Line 133:                 df.to_csv(f, index=True)",
                "// Line 134: ",
                "// Line 135:     def save_visualizations(",
                "// Line 136:         self, df: Union[pd.DataFrame, pd.Series]",
                "// Line 137:     ) -> Dict[str, VisualizationType]:",
                "// Line 138:         \"\"\"Save visualizations of the given pandas dataframe or series.",
                "// Line 139: ",
                "// Line 140:         Args:",
                "// Line 141:             df: The pandas dataframe or series to visualize.",
                "// Line 142: ",
                "// Line 143:         Returns:",
                "// Line 144:             A dictionary of visualization URIs and their types.",
                "// Line 145:         \"\"\"",
                "// Line 146:         describe_uri = os.path.join(self.uri, \"describe.csv\")",
                "// Line 147:         describe_uri = describe_uri.replace(\"\", \"/\")",
                "// vulnerable line: 148: with fileio.open(describe_uri, mode=\"wb\") as f:",
                "// Line 149:             df.describe().to_csv(f)",
                "// Line 150:         return {describe_uri: VisualizationType.CSV}",
                "// Line 151: ",
                "// Line 152:     def extract_metadata(",
                "// Line 153:         self, df: Union[pd.DataFrame, pd.Series]",
                "// Line 154:     ) -> Dict[str, \"MetadataType\"]:",
                "// Line 155:         \"\"\"Extract metadata from the given pandas dataframe or series.",
                "// Line 156: ",
                "// Line 157:         Args:",
                "// Line 158:             df: The pandas dataframe or series to extract metadata from."
            ]
        },
        {
            "filename_of_changes": "service_materializer.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "5",
            "number_of_lines_deleted_vulnerable_to_cve": "3",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 10: #  distributed under the License is distributed on an \"AS IS\" BASIS,",
                "// Line 11: #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
                "// Line 12: #  or implied. See the License for the specific language governing",
                "// Line 13: #  permissions and limitations under the License.",
                "// Line 14: \"\"\"Implementation of a materializer to read and write ZenML service instances.\"\"\"",
                "// Line 15: ",
                "// Line 16: import os",
                "// Line 17: from typing import TYPE_CHECKING, Any, ClassVar, Dict, Tuple, Type",
                "// Line 18: ",
                "// Line 19: from zenml.enums import ArtifactType",
                "// vulnerable line: 20: from zenml.io import fileio",
                "// Line 21: from zenml.materializers.base_materializer import BaseMaterializer",
                "// Line 22: from zenml.services.service import BaseService",
                "// Line 23: from zenml.services.service_registry import ServiceRegistry",
                "// Line 24: ",
                "// Line 25: if TYPE_CHECKING:",
                "// Line 26:     from zenml.metadata.metadata_types import MetadataType",
                "// Line 27: ",
                "// Line 28: SERVICE_CONFIG_FILENAME = \"service.json\"",
                "// Line 29: ",
                "// Line 30: ",
                "// Line 40:         This service is instantiated from the serialized service configuration",
                "// Line 41:         and last known status information saved as artifact.",
                "// Line 42: ",
                "// Line 43:         Args:",
                "// Line 44:             data_type: The type of the data to read.",
                "// Line 45: ",
                "// Line 46:         Returns:",
                "// Line 47:             A ZenML service instance.",
                "// Line 48:         \"\"\"",
                "// Line 49:         filepath = os.path.join(self.uri, SERVICE_CONFIG_FILENAME)",
                "// vulnerable line: 50: with fileio.open(filepath, \"r\") as f:",
                "// Line 51:             service = ServiceRegistry().load_service_from_json(f.read())",
                "// Line 52:         return service",
                "// Line 53: ",
                "// Line 54:     def save(self, service: BaseService) -> None:",
                "// Line 55:         \"\"\"Writes a ZenML service.",
                "// Line 56: ",
                "// Line 57:         The configuration and last known status of the input service instance",
                "// Line 58:         are serialized and saved as an artifact.",
                "// Line 59: ",
                "// Line 60:         Args:",
                "// Line 61:             service: A ZenML service instance.",
                "// Line 62:         \"\"\"",
                "// Line 63:         filepath = os.path.join(self.uri, SERVICE_CONFIG_FILENAME)",
                "// vulnerable line: 64: with fileio.open(filepath, \"w\") as f:",
                "// Line 65:             f.write(service.json(indent=4))",
                "// Line 66: ",
                "// Line 67:     def extract_metadata(",
                "// Line 68:         self, service: BaseService",
                "// Line 69:     ) -> Dict[str, \"MetadataType\"]:",
                "// Line 70:         \"\"\"Extract metadata from the given service.",
                "// Line 71: ",
                "// Line 72:         Args:",
                "// Line 73:             service: The service to extract metadata from.",
                "// Line 74: "
            ]
        },
        {
            "filename_of_changes": "step_logging.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "8",
            "number_of_lines_deleted_vulnerable_to_cve": "6",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 16: import os",
                "// Line 17: import re",
                "// Line 18: import sys",
                "// Line 19: import time",
                "// Line 20: from contextvars import ContextVar",
                "// Line 21: from types import TracebackType",
                "// Line 22: from typing import Any, Callable, List, Optional, Type",
                "// Line 23: from uuid import uuid4",
                "// Line 24: ",
                "// Line 25: from zenml.artifact_stores import BaseArtifactStore",
                "// vulnerable line: 26: from zenml.io import fileio",
                "// Line 27: from zenml.logger import get_logger",
                "// Line 28: from zenml.logging import (",
                "// Line 29:     STEP_LOGS_STORAGE_INTERVAL_SECONDS,",
                "// Line 30:     STEP_LOGS_STORAGE_MAX_MESSAGES,",
                "// Line 31: )",
                "// Line 32: ",
                "// Line 33: # Get the logger",
                "// Line 34: logger = get_logger(__name__)",
                "// Line 35: ",
                "// Line 36: redirected: ContextVar[bool] = ContextVar(\"redirected\", default=False)",
                "// Line 67:     if log_key is None:",
                "// Line 68:         log_key = str(uuid4())",
                "// Line 69: ",
                "// Line 70:     logs_base_uri = os.path.join(",
                "// Line 71:         artifact_store.path,",
                "// Line 72:         step_name,",
                "// Line 73:         \"logs\",",
                "// Line 74:     )",
                "// Line 75: ",
                "// Line 76:     # Create the dir",
                "// vulnerable line: 77: if not fileio.exists(logs_base_uri):",
                "// vulnerable line: 78: fileio.makedirs(logs_base_uri)",
                "// Line 79: ",
                "// Line 80:     # Delete the file if it already exists",
                "// Line 81:     logs_uri = os.path.join(logs_base_uri, f\"{log_key}.log\")",
                "// vulnerable line: 82: if fileio.exists(logs_uri):",
                "// Line 83:         logger.warning(",
                "// Line 84:             f\"Logs file {logs_uri} already exists! Removing old log file...\"",
                "// Line 85:         )",
                "// vulnerable line: 86: fileio.remove(logs_uri)",
                "// Line 87:     return logs_uri",
                "// Line 88: ",
                "// Line 89: ",
                "// Line 90: class StepLogsStorage:",
                "// Line 91:     \"\"\"Helper class which buffers and stores logs to a given URI.\"\"\"",
                "// Line 92: ",
                "// Line 93:     def __init__(",
                "// Line 94:         self,",
                "// Line 95:         logs_uri: str,",
                "// Line 96:         max_messages: int = STEP_LOGS_STORAGE_MAX_MESSAGES,",
                "// Line 134:             ):",
                "// Line 135:                 self.save_to_file()",
                "// Line 136: ",
                "// Line 137:     def save_to_file(self) -> None:",
                "// Line 138:         \"\"\"Method to save the buffer to the given URI.\"\"\"",
                "// Line 139:         if not self.disabled:",
                "// Line 140:             try:",
                "// Line 141:                 self.disabled = True",
                "// Line 142: ",
                "// Line 143:                 if self.buffer:",
                "// vulnerable line: 144: with fileio.open(self.logs_uri, \"a\") as file:",
                "// Line 145:                         for message in self.buffer:",
                "// Line 146:                             file.write(",
                "// Line 147:                                 remove_ansi_escape_codes(message) + \"",
                "// Line 148: \"",
                "// Line 149:                             )",
                "// Line 150: ",
                "// Line 151:             except (OSError, IOError) as e:",
                "// Line 152:                 # This exception can be raised if there are issues with the",
                "// Line 153:                 # underlying system calls, such as reaching the maximum number",
                "// Line 154:                 # of open files, permission issues, file corruption, or other"
            ]
        },
        {
            "filename_of_changes": "structured_string_materializer.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "5",
            "number_of_lines_deleted_vulnerable_to_cve": "3",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 10: #  distributed under the License is distributed on an \"AS IS\" BASIS,",
                "// Line 11: #  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express",
                "// Line 12: #  or implied. See the License for the specific language governing",
                "// Line 13: #  permissions and limitations under the License.",
                "// Line 14: \"\"\"Implementation of HTMLString materializer.\"\"\"",
                "// Line 15: ",
                "// Line 16: import os",
                "// Line 17: from typing import Dict, Type, Union",
                "// Line 18: ",
                "// Line 19: from zenml.enums import ArtifactType, VisualizationType",
                "// vulnerable line: 20: from zenml.io import fileio",
                "// Line 21: from zenml.logger import get_logger",
                "// Line 22: from zenml.materializers.base_materializer import BaseMaterializer",
                "// Line 23: from zenml.types import CSVString, HTMLString, MarkdownString",
                "// Line 24: ",
                "// Line 25: logger = get_logger(__name__)",
                "// Line 26: ",
                "// Line 27: ",
                "// Line 28: STRUCTURED_STRINGS = Union[CSVString, HTMLString, MarkdownString]",
                "// Line 29: ",
                "// Line 30: HTML_FILENAME = \"output.html\"",
                "// Line 40: ",
                "// Line 41:     def load(self, data_type: Type[STRUCTURED_STRINGS]) -> STRUCTURED_STRINGS:",
                "// Line 42:         \"\"\"Loads the data from the HTML or Markdown file.",
                "// Line 43: ",
                "// Line 44:         Args:",
                "// Line 45:             data_type: The type of the data to read.",
                "// Line 46: ",
                "// Line 47:         Returns:",
                "// Line 48:             The loaded data.",
                "// Line 49:         \"\"\"",
                "// vulnerable line: 50: with fileio.open(self._get_filepath(data_type), \"r\") as f:",
                "// Line 51:             return data_type(f.read())",
                "// Line 52: ",
                "// Line 53:     def save(self, data: STRUCTURED_STRINGS) -> None:",
                "// Line 54:         \"\"\"Save data as an HTML or Markdown file.",
                "// Line 55: ",
                "// Line 56:         Args:",
                "// Line 57:             data: The data to save as an HTML or Markdown file.",
                "// Line 58:         \"\"\"",
                "// vulnerable line: 59: with fileio.open(self._get_filepath(type(data)), \"w\") as f:",
                "// Line 60:             f.write(data)",
                "// Line 61: ",
                "// Line 62:     def save_visualizations(",
                "// Line 63:         self, data: STRUCTURED_STRINGS",
                "// Line 64:     ) -> Dict[str, VisualizationType]:",
                "// Line 65:         \"\"\"Save visualizations for the given data.",
                "// Line 66: ",
                "// Line 67:         Args:",
                "// Line 68:             data: The data to save visualizations for.",
                "// Line 69: "
            ]
        },
        {
            "filename_of_changes": "test_built_in_materializer.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "7",
            "number_of_lines_deleted_vulnerable_to_cve": "2",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 183: ",
                "// Line 184:     def save(self, data: CustomType) -> None:",
                "// Line 185:         \"\"\"Save the data (not).\"\"\"",
                "// Line 186:         pass",
                "// Line 187: ",
                "// Line 188:     def load(self, data_type: Type[CustomType]) -> Optional[CustomType]:",
                "// Line 189:         \"\"\"Load the data.\"\"\"",
                "// Line 190:         return data_type()",
                "// Line 191: ",
                "// Line 192: ",
                "// vulnerable line: 193: def test_container_materializer_for_custom_types(mocker):",
                "// Line 194:     \"\"\"Test container materializer for custom types.",
                "// Line 195: ",
                "// Line 196:     This ensures that:",
                "// Line 197:     - The container materializer can handle custom types.",
                "// Line 198:     - Custom types are loaded as the correct type.",
                "// Line 199:     - The materializer of the subtype does not need to be registered in the",
                "// Line 200:         materializer registry when the container is loaded.",
                "// Line 201:     \"\"\"",
                "// Line 202:     from zenml.materializers.materializer_registry import materializer_registry",
                "// Line 203: ",
                "// Line 204:     example = [CustomType(), CustomSubType()]",
                "// vulnerable line: 205: with TemporaryDirectory() as artifact_uri:",
                "// Line 206:         materializer = BuiltInContainerMaterializer(uri=artifact_uri)",
                "// Line 207: ",
                "// Line 208:         # Container materializer should find materializer for both elements in",
                "// Line 209:         # the default materializer registry.",
                "// Line 210:         materializer.save(example)",
                "// Line 211: ",
                "// Line 212:         # When loading, the default materializer registry should no longer be",
                "// Line 213:         # needed because the container materializer should have saved the",
                "// Line 214:         # materializer that was used for each element.",
                "// Line 215:         mocker.patch.object("
            ]
        },
        {
            "filename_of_changes": "test_cloudpickle_materializer.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "3",
            "number_of_lines_deleted_vulnerable_to_cve": "1",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 35: def test_cloudpickle_materializer(clean_client):",
                "// Line 36:     \"\"\"Test that the cloudpickle materializer is used if no other is found.\"\"\"",
                "// Line 37:     output = _test_materializer(",
                "// Line 38:         step_output=Unmaterializable(), expected_metadata_size=1",
                "// Line 39:     )",
                "// Line 40:     assert output.cat == \"aria\"",
                "// Line 41: ",
                "// Line 42: ",
                "// Line 43: def test_cloudpickle_materializer_python_version_check(clean_client):",
                "// Line 44:     \"\"\"Test that the cloudpickle materializer saves the Python version.\"\"\"",
                "// vulnerable line: 45: with TemporaryDirectory() as artifact_uri:",
                "// Line 46:         materializer = CloudpickleMaterializer(uri=artifact_uri)",
                "// Line 47:         materializer._save_python_version()",
                "// Line 48:         version = materializer._load_python_version()",
                "// Line 49:         assert version == Environment().python_version()",
                "// Line 50: ",
                "// Line 51: ",
                "// Line 52: def test_cloudpickle_materializer_is_not_registered(clean_client):",
                "// Line 53:     \"\"\"Test that the cloudpickle materializer is not registered by default.\"\"\"",
                "// Line 54:     assert (",
                "// Line 55:         CloudpickleMaterializer",
                "// Line 56:         not in materializer_registry.materializer_types.values()",
                "// Line 57:     )",
                "// Line 58: ",
                "// Line 59: ",
                "// Line 60: def test_cloudpickle_materializer_can_load_pickle(clean_client):",
                "// Line 61:     \"\"\"Test that the cloudpickle materializer can load regular pickle.\"\"\"",
                "// Line 62:     my_object = Unmaterializable()",
                "// vulnerable line: 63: with TemporaryDirectory() as artifact_uri:",
                "// Line 64:         artifact_filepath = os.path.join(artifact_uri, DEFAULT_FILENAME)",
                "// Line 65:         with open(artifact_filepath, \"wb\") as f:",
                "// Line 66:             pickle.dump(my_object, f)",
                "// Line 67:         materializer = CloudpickleMaterializer(uri=artifact_uri)",
                "// Line 68:         loaded_object = materializer.load(data_type=Unmaterializable)",
                "// Line 69:         assert loaded_object.cat == \"aria\""
            ]
        },
        {
            "filename_of_changes": "test_general.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "3",
            "number_of_lines_deleted_vulnerable_to_cve": "1",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 69: ",
                "// Line 70:     Returns:",
                "// Line 71:         The result of materializing `step_output` to disk and loading it again.",
                "// Line 72:     \"\"\"",
                "// Line 73:     if step_output_type is None:",
                "// Line 74:         step_output_type = type(step_output)",
                "// Line 75: ",
                "// Line 76:     if materializer_class is None:",
                "// Line 77:         materializer_class = materializer_registry[step_output_type]",
                "// Line 78: ",
                "// vulnerable line: 79: with TemporaryDirectory() as artifact_uri:",
                "// Line 80:         materializer = materializer_class(uri=artifact_uri)",
                "// Line 81:         existing_files = os.listdir(artifact_uri)",
                "// Line 82: ",
                "// Line 83:         # Assert that materializer saves something to disk",
                "// Line 84:         materializer.save(step_output)",
                "// Line 85:         if assert_data_exists:",
                "// Line 86:             new_files = os.listdir(artifact_uri)",
                "// Line 87:             assert len(new_files) > len(existing_files)",
                "// Line 88: ",
                "// Line 89:         # Assert that visualization extraction returns a dict"
            ]
        },
        {
            "filename_of_changes": "test_utils.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "1",
            "number_of_lines_deleted_vulnerable_to_cve": "1",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 255: ",
                "// Line 256:     @pipeline",
                "// Line 257:     def artifact_metadata_logging_pipeline():",
                "// Line 258:         wrong_artifact_multi_output_metadata_logging_step()",
                "// Line 259: ",
                "// Line 260:     with pytest.raises(ValueError):",
                "// Line 261:         artifact_metadata_logging_pipeline()",
                "// Line 262: ",
                "// Line 263: ",
                "// Line 264: def test_download_artifact_files_from_response(",
                "// vulnerable line: 265: tmp_path, clean_client_with_run",
                "// Line 266: ):",
                "// Line 267:     \"\"\"Test that we can download artifact files from an artifact version.\"\"\"",
                "// Line 268:     artifact: ArtifactResponse = clean_client_with_run.get_artifact(",
                "// Line 269:         name_id_or_prefix=\"connected_two_step_pipeline::step_1::output\"",
                "// Line 270:     )",
                "// Line 271:     artifact_version_id = list(artifact.versions.values())[0].id",
                "// Line 272:     av = clean_client_with_run.get_artifact_version(artifact_version_id)",
                "// Line 273:     # create temporary path ending in .zip",
                "// Line 274: ",
                "// Line 275:     zipfile_path = os.path.join(tmp_path, \"some_file.zip\")",
                "// Line 280:     with zipfile.ZipFile(zipfile_path, \"r\") as zip_ref:",
                "// Line 281:         zip_ref.extractall(tmp_path)",
                "// Line 282:     with open(os.path.join(tmp_path, \"data.json\"), \"r\") as f:",
                "// Line 283:         assert f.read() == \"7\"",
                "// Line 284: ",
                "// Line 285:     # clean up",
                "// Line 286:     shutil.rmtree(tmp_path)",
                "// Line 287: ",
                "// Line 288: ",
                "// Line 289: def test_download_artifact_files_from_response_fails_if_exists(",
                "// vulnerable line: 290: tmp_path, clean_client_with_run",
                "// Line 291: ):",
                "// Line 292:     \"\"\"Test that downloading artifact files from an artifact version fails.",
                "// Line 293: ",
                "// Line 294:     Failure when the file already exists and `overwrite` is False.\"\"\"",
                "// Line 295:     artifact: ArtifactResponse = clean_client_with_run.get_artifact(",
                "// Line 296:         name_id_or_prefix=\"connected_two_step_pipeline::step_1::output\"",
                "// Line 297:     )",
                "// Line 298:     artifact_version_id = list(artifact.versions.values())[0].id",
                "// Line 299:     av = clean_client_with_run.get_artifact_version(artifact_version_id)",
                "// Line 300:     # create temporary path ending in .zip"
            ]
        },
        {
            "filename_of_changes": "test_utils.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "9",
            "number_of_lines_deleted_vulnerable_to_cve": "4",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 58:     # Read the contents of the file",
                "// Line 59:     with open(file_path, \"r\") as f:",
                "// Line 60:         file_contents = f.read()",
                "// Line 61:         assert \"datatype\" in file_contents",
                "// Line 62:         assert model_artifact.data_type in file_contents",
                "// Line 63:         assert \"materializer\" in file_contents",
                "// Line 64:         assert model_artifact.materializer in file_contents",
                "// Line 65: ",
                "// Line 66: ",
                "// Line 67: @pytest.fixture",
                "// vulnerable line: 68: def model_metadata_dir(model_artifact):",
                "// Line 69:     # Save the model metadata to a temporary file",
                "// Line 70:     file_path = save_model_metadata(model_artifact)",
                "// Line 71: ",
                "// Line 72:     # Move the file to a temporary directory",
                "// vulnerable line: 73: temp_dir = tempfile.mkdtemp()",
                "// Line 74:     shutil.move(",
                "// Line 75:         file_path, os.path.join(temp_dir, MODEL_METADATA_YAML_FILE_NAME)",
                "// Line 76:     )",
                "// Line 77: ",
                "// Line 78:     # Yield the temporary directory",
                "// Line 79:     yield temp_dir",
                "// Line 80: ",
                "// Line 81:     # Cleanup",
                "// Line 82:     shutil.rmtree(temp_dir)",
                "// Line 83: ",
                "// Line 112:         \"zenml.artifacts.utils._load_artifact_from_uri\", return_value=model",
                "// Line 113:     )",
                "// Line 114: ",
                "// Line 115:     load_artifact_from_response(model_artifact)",
                "// Line 116: ",
                "// Line 117:     # Ensure the _load_artifact_from_uri function is called",
                "// Line 118:     mocker_load_artifact.assert_called_once()",
                "// Line 119: ",
                "// Line 120: ",
                "// Line 121: @pytest.fixture",
                "// vulnerable line: 122: def numpy_file_uri():",
                "// Line 123:     # Create a temporary file to save the numpy array",
                "// vulnerable line: 124: temp_dir = tempfile.mkdtemp()",
                "// Line 125:     numpy_file = os.path.join(temp_dir, NUMPY_FILENAME)",
                "// Line 126: ",
                "// Line 127:     # Save a numpy array to the temporary file",
                "// Line 128:     arr = np.array([1, 2, 3, 4, 5])",
                "// Line 129:     np.save(numpy_file, arr)",
                "// Line 130: ",
                "// Line 131:     # Yield the temporary directory",
                "// Line 132:     yield temp_dir",
                "// Line 133: ",
                "// Line 134:     # Cleanup"
            ]
        },
        {
            "filename_of_changes": "utils.py",
            "code_language": "Python",
            "number_of_lines_added_for_mitigation": "7",
            "number_of_lines_deleted_vulnerable_to_cve": "3",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 145: ",
                "// Line 146:     # Get the current artifact store",
                "// Line 147:     artifact_store = client.active_stack.artifact_store",
                "// Line 148: ",
                "// Line 149:     # Build and check the artifact URI",
                "// Line 150:     if not uri:",
                "// Line 151:         uri = os.path.join(\"custom_artifacts\", name, str(uuid4()))",
                "// Line 152:     if not uri.startswith(artifact_store.path):",
                "// Line 153:         uri = os.path.join(artifact_store.path, uri)",
                "// Line 154: ",
                "// vulnerable line: 155: if manual_save and fileio.exists(uri):",
                "// Line 156:         # This check is only necessary for manual saves as we already check",
                "// Line 157:         # it when creating the directory for step output artifacts",
                "// Line 158:         other_artifacts = client.list_artifact_versions(uri=uri, size=1)",
                "// Line 159:         if other_artifacts and (other_artifact := other_artifacts[0]):",
                "// Line 160:             raise RuntimeError(",
                "// Line 161:                 f\"Cannot save new artifact {name} version to URI \"",
                "// Line 162:                 f\"{uri} because the URI is already used by artifact \"",
                "// Line 163:                 f\"{other_artifact.name} (version {other_artifact.version}).\"",
                "// Line 164:             )",
                "// vulnerable line: 165: fileio.makedirs(uri)",
                "// Line 166: ",
                "// Line 167:     # Find and initialize the right materializer class",
                "// Line 168:     if isinstance(materializer, type):",
                "// Line 169:         materializer_class = materializer",
                "// Line 170:     elif materializer:",
                "// Line 171:         materializer_class = source_utils.load_and_validate_class(",
                "// Line 172:             materializer, expected_class=BaseMaterializer",
                "// Line 173:         )",
                "// Line 174:     else:",
                "// Line 175:         materializer_class = materializer_registry[type(data)]",
                "// Line 812:     by the save_model_metadata function. The information in the Yaml file is",
                "// Line 813:     used to load the model into memory in the inference environment.",
                "// Line 814: ",
                "// Line 815:     Args:",
                "// Line 816:         model_uri: the artifact to extract the metadata from.",
                "// Line 817: ",
                "// Line 818:     Returns:",
                "// Line 819:         The ML model object loaded into memory.",
                "// Line 820:     \"\"\"",
                "// Line 821:     # Load the model from its metadata",
                "// vulnerable line: 822: with fileio.open(",
                "// Line 823:         os.path.join(model_uri, MODEL_METADATA_YAML_FILE_NAME), \"r\"",
                "// Line 824:     ) as f:",
                "// Line 825:         metadata = read_yaml(f.name)",
                "// Line 826:     data_type = metadata[\"datatype\"]",
                "// Line 827:     materializer = metadata[\"materializer\"]",
                "// Line 828:     model = _load_artifact_from_uri(",
                "// Line 829:         materializer=materializer, data_type=data_type, uri=model_uri",
                "// Line 830:     )",
                "// Line 831: ",
                "// Line 832:     # Switch to eval mode if the model is a torch model"
            ]
        }
    ]
}