{
    "cve_id": "CVE-2024-4287",
    "cve_description": "In mintplex-labs/anything-llm, a vulnerability exists due to improper input validation in the workspace update process. Specifically, the application fails to validate or format JSON data sent in an HTTP POST request to `/api/workspace/:workspace-slug/update`, allowing it to be executed as part of a database query without restrictions. This flaw enables users with a manager role to craft a request that includes nested write operations, effectively allowing them to create new Administrator accounts.",
    "cve_publish_date": "2024-05-20T13:15Z",
    "cwe_id": "CWE-20",
    "cwe_name": "Improper Input Validation",
    "cwe_description": "The product receives input or data, but it does\n        not validate or incorrectly validates that the input has the\n        properties that are required to process the data safely and\n        correctly.",
    "commit_message": "Enable per-workspace provider/model combination (#1042)\n\n* Enable per-workspace provider/model combination\r\n\r\n* cleanup\r\n\r\n* remove resetWorkspaceChatModels and wipeWorkspaceModelPreference to prevent workspace from resetting model\r\n\r\n* add space\r\n\r\n---------\r\n\r\nCo-authored-by: shatfield4 <seanhatfield5@gmail.com>",
    "type_of_change": "Modification",
    "changes": [
        {
            "filename_of_changes": "index.js",
            "code_language": "JavaScript",
            "number_of_lines_added_for_mitigation": "18",
            "number_of_lines_deleted_vulnerable_to_cve": "17",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 1: function getVectorDbClass() {",
                "// Line 2:   const vectorSelection = process.env.VECTOR_DB || \"pinecone\";",
                "// vulnerable line: 3: switch (vectorSelection) {",
                "// Line 4:     case \"pinecone\":",
                "// Line 5:       const { Pinecone } = require(\"../vectorDbProviders/pinecone\");",
                "// Line 6:       return Pinecone;",
                "// Line 7:     case \"chroma\":",
                "// Line 8:       const { Chroma } = require(\"../vectorDbProviders/chroma\");",
                "// Line 9:       return Chroma;",
                "// Line 10:     case \"lancedb\":",
                "// Line 11:       const { LanceDb } = require(\"../vectorDbProviders/lance\");",
                "// Line 12:       return LanceDb;",
                "// Line 13:     case \"weaviate\":",
                "// Line 23:       const { Zilliz } = require(\"../vectorDbProviders/zilliz\");",
                "// Line 24:       return Zilliz;",
                "// Line 25:     case \"astra\":",
                "// Line 26:       const { AstraDB } = require(\"../vectorDbProviders/astra\");",
                "// Line 27:       return AstraDB;",
                "// Line 28:     default:",
                "// Line 29:       throw new Error(\"ENV: No VECTOR_DB value found in environment!\");",
                "// Line 30:   }",
                "// Line 31: }",
                "// Line 32: ",
                "// vulnerable line: 33: function getLLMProvider(modelPreference = null) {",
                "// vulnerable line: 34: const vectorSelection = process.env.LLM_PROVIDER || \"openai\";",
                "// Line 35:   const embedder = getEmbeddingEngineSelection();",
                "// vulnerable line: 36: switch (vectorSelection) {",
                "// Line 37:     case \"openai\":",
                "// Line 38:       const { OpenAiLLM } = require(\"../AiProviders/openAi\");",
                "// vulnerable line: 39: return new OpenAiLLM(embedder, modelPreference);",
                "// Line 40:     case \"azure\":",
                "// Line 41:       const { AzureOpenAiLLM } = require(\"../AiProviders/azureOpenAi\");",
                "// vulnerable line: 42: return new AzureOpenAiLLM(embedder, modelPreference);",
                "// Line 43:     case \"anthropic\":",
                "// Line 44:       const { AnthropicLLM } = require(\"../AiProviders/anthropic\");",
                "// vulnerable line: 45: return new AnthropicLLM(embedder, modelPreference);",
                "// Line 46:     case \"gemini\":",
                "// Line 47:       const { GeminiLLM } = require(\"../AiProviders/gemini\");",
                "// vulnerable line: 48: return new GeminiLLM(embedder, modelPreference);",
                "// Line 49:     case \"lmstudio\":",
                "// Line 50:       const { LMStudioLLM } = require(\"../AiProviders/lmStudio\");",
                "// vulnerable line: 51: return new LMStudioLLM(embedder, modelPreference);",
                "// Line 52:     case \"localai\":",
                "// Line 53:       const { LocalAiLLM } = require(\"../AiProviders/localAi\");",
                "// vulnerable line: 54: return new LocalAiLLM(embedder, modelPreference);",
                "// Line 55:     case \"ollama\":",
                "// Line 56:       const { OllamaAILLM } = require(\"../AiProviders/ollama\");",
                "// vulnerable line: 57: return new OllamaAILLM(embedder, modelPreference);",
                "// Line 58:     case \"togetherai\":",
                "// Line 59:       const { TogetherAiLLM } = require(\"../AiProviders/togetherAi\");",
                "// vulnerable line: 60: return new TogetherAiLLM(embedder, modelPreference);",
                "// Line 61:     case \"perplexity\":",
                "// Line 62:       const { PerplexityLLM } = require(\"../AiProviders/perplexity\");",
                "// vulnerable line: 63: return new PerplexityLLM(embedder, modelPreference);",
                "// Line 64:     case \"openrouter\":",
                "// Line 65:       const { OpenRouterLLM } = require(\"../AiProviders/openRouter\");",
                "// vulnerable line: 66: return new OpenRouterLLM(embedder, modelPreference);",
                "// Line 67:     case \"mistral\":",
                "// Line 68:       const { MistralLLM } = require(\"../AiProviders/mistral\");",
                "// vulnerable line: 69: return new MistralLLM(embedder, modelPreference);",
                "// Line 70:     case \"native\":",
                "// Line 71:       const { NativeLLM } = require(\"../AiProviders/native\");",
                "// vulnerable line: 72: return new NativeLLM(embedder, modelPreference);",
                "// Line 73:     case \"huggingface\":",
                "// Line 74:       const { HuggingFaceLLM } = require(\"../AiProviders/huggingface\");",
                "// vulnerable line: 75: return new HuggingFaceLLM(embedder, modelPreference);",
                "// Line 76:     case \"groq\":",
                "// Line 77:       const { GroqLLM } = require(\"../AiProviders/groq\");",
                "// vulnerable line: 78: return new GroqLLM(embedder, modelPreference);",
                "// Line 79:     default:",
                "// Line 80:       throw new Error(\"ENV: No LLM_PROVIDER value found in environment!\");",
                "// Line 81:   }",
                "// Line 82: }",
                "// Line 83: ",
                "// Line 84: function getEmbeddingEngineSelection() {",
                "// Line 85:   const engineSelection = process.env.EMBEDDING_ENGINE;",
                "// Line 86:   switch (engineSelection) {",
                "// Line 87:     case \"openai\":",
                "// Line 88:       const { OpenAiEmbedder } = require(\"../EmbeddingEngines/openAi\");"
            ]
        },
        {
            "filename_of_changes": "index.jsx",
            "code_language": "JavaScript",
            "number_of_lines_added_for_mitigation": "21",
            "number_of_lines_deleted_vulnerable_to_cve": "19",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 1: export default function GroqAiOptions({ settings }) {",
                "// vulnerable line: 2: return (",
                "// Line 3:     <div className=\"flex gap-x-4\">",
                "// vulnerable line: 4: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 5: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// Line 6:           Groq API Key",
                "// vulnerable line: 7: </label>",
                "// Line 8:         <input",
                "// Line 9:           type=\"password\"",
                "// Line 10:           name=\"GroqApiKey\"",
                "// Line 11:           className=\"bg-zinc-900 text-white placeholder:text-white/20 text-sm rounded-lg focus:border-white block w-full p-2.5\"",
                "// Line 12:           placeholder=\"Groq API Key\"",
                "// Line 13:           defaultValue={settings?.GroqApiKey ? \"*\".repeat(20) : \"\"}",
                "// vulnerable line: 14: required={true}",
                "// Line 15:           autoComplete=\"off\"",
                "// Line 16:           spellCheck={false}",
                "// Line 17:         />",
                "// vulnerable line: 18: </div>",
                "// Line 19: ",
                "// vulnerable line: 20: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 21: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// vulnerable line: 22: Chat Model Selection",
                "// vulnerable line: 23: </label>",
                "// vulnerable line: 24: <select",
                "// vulnerable line: 25: name=\"GroqModelPref\"",
                "// vulnerable line: 26: defaultValue={settings?.GroqModelPref || \"llama2-70b-4096\"}",
                "// vulnerable line: 27: required={true}",
                "// vulnerable line: 28: className=\"bg-zinc-900 border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"",
                "// vulnerable line: 29: >",
                "// vulnerable line: 30: {[\"llama2-70b-4096\", \"mixtral-8x7b-32768\"].map((model) => {",
                "// vulnerable line: 31: return (",
                "// vulnerable line: 32: <option key={model} value={model}>",
                "// vulnerable line: 33: {model}",
                "// vulnerable line: 34: </option>",
                "// vulnerable line: 35: );",
                "// vulnerable line: 36: })}",
                "// vulnerable line: 37: </select>",
                "// vulnerable line: 38: </div>",
                "// vulnerable line: 39: </div>",
                "// vulnerable line: 40: );",
                "// Line 41: }"
            ]
        },
        {
            "filename_of_changes": "index.jsx",
            "code_language": "JavaScript",
            "number_of_lines_added_for_mitigation": "21",
            "number_of_lines_deleted_vulnerable_to_cve": "17",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 12:   return (",
                "// Line 13:     <div className=\"w-full flex flex-col\">",
                "// Line 14:       {showAlert && (",
                "// Line 15:         <div className=\"flex flex-col md:flex-row md:items-center gap-x-2 text-white mb-6 bg-blue-800/30 w-fit rounded-lg px-4 py-2\">",
                "// Line 16:           <div className=\"gap-x-2 flex items-center\">",
                "// Line 17:             <Info size={12} className=\"hidden md:visible\" />",
                "// Line 18:             <p className=\"text-sm md:text-base\">",
                "// Line 19:               LMStudio as your LLM requires you to set an embedding service to",
                "// Line 20:               use.",
                "// Line 21:             </p>",
                "// vulnerable line: 22: </div>",
                "// Line 23:           <a",
                "// Line 24:             href={paths.settings.embeddingPreference()}",
                "// Line 25:             className=\"text-sm md:text-base my-2 underline\"",
                "// Line 26:           >",
                "// Line 27:             Manage embedding &rarr;",
                "// Line 28:           </a>",
                "// vulnerable line: 29: </div>",
                "// Line 30:       )}",
                "// Line 31:       <div className=\"w-full flex items-center gap-4\">",
                "// vulnerable line: 32: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 33: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// Line 34:             LMStudio Base URL",
                "// vulnerable line: 35: </label>",
                "// vulnerable line: 36: <input",
                "// Line 37:             type=\"url\"",
                "// Line 38:             name=\"LMStudioBasePath\"",
                "// vulnerable line: 39: className=\"bg-zinc-900 text-white placeholder:text-white/20 text-sm rounded-lg focus:border-white block w-full p-2.5\"",
                "// Line 40:             placeholder=\"http://localhost:1234/v1\"",
                "// Line 41:             defaultValue={settings?.LMStudioBasePath}",
                "// vulnerable line: 42: required={true}",
                "// vulnerable line: 43: autoComplete=\"off\"",
                "// Line 44:             spellCheck={false}",
                "// Line 45:             onChange={(e) => setBasePathValue(e.target.value)}",
                "// Line 46:             onBlur={() => setBasePath(basePathValue)}",
                "// vulnerable line: 47: />",
                "// vulnerable line: 48: </div>",
                "// vulnerable line: 49: <LMStudioModelSelection settings={settings} basePath={basePath} />",
                "// vulnerable line: 50: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 51: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// vulnerable line: 52: Token context window",
                "// vulnerable line: 53: </label>",
                "// vulnerable line: 54: <input",
                "// vulnerable line: 55: type=\"number\"",
                "// vulnerable line: 56: name=\"LMStudioTokenLimit\"",
                "// vulnerable line: 57: className=\"bg-zinc-900 text-white placeholder:text-white/20 text-sm rounded-lg focus:border-white block w-full p-2.5\"",
                "// vulnerable line: 58: placeholder=\"4096\"",
                "// vulnerable line: 59: min={1}",
                "// vulnerable line: 60: onScroll={(e) => e.target.blur()}",
                "// vulnerable line: 61: defaultValue={settings?.LMStudioTokenLimit}",
                "// vulnerable line: 62: required={true}",
                "// vulnerable line: 63: autoComplete=\"off\"",
                "// vulnerable line: 64: />",
                "// vulnerable line: 65: </div>",
                "// vulnerable line: 66: </div>",
                "// vulnerable line: 67: </div>",
                "// Line 68:   );",
                "// Line 69: }",
                "// Line 70: ",
                "// Line 71: function LMStudioModelSelection({ settings, basePath = null }) {",
                "// Line 72:   const [customModels, setCustomModels] = useState([]);",
                "// Line 73:   const [loading, setLoading] = useState(true);",
                "// Line 74: ",
                "// Line 75:   useEffect(() => {",
                "// Line 76:     async function findCustomModels() {",
                "// Line 77:       if (!basePath || !basePath.includes(\"/v1\")) {",
                "// Line 82:       setLoading(true);",
                "// Line 83:       const { models } = await System.customModels(\"lmstudio\", null, basePath);",
                "// Line 84:       setCustomModels(models || []);",
                "// Line 85:       setLoading(false);",
                "// Line 86:     }",
                "// Line 87:     findCustomModels();",
                "// Line 88:   }, [basePath]);",
                "// Line 89: ",
                "// Line 90:   if (loading || customModels.length == 0) {",
                "// Line 91:     return (",
                "// vulnerable line: 92: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 93: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// Line 94:           Chat Model Selection",
                "// vulnerable line: 95: </label>",
                "// Line 96:         <select",
                "// Line 97:           name=\"LMStudioModelPref\"",
                "// Line 98:           disabled={true}",
                "// Line 99:           className=\"bg-zinc-900 border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"",
                "// Line 100:         >",
                "// Line 101:           <option disabled={true} selected={true}>",
                "// Line 102:             {basePath?.includes(\"/v1\")",
                "// Line 103:               ? \"-- loading available models --\"",
                "// Line 104:               : \"-- waiting for URL --\"}",
                "// Line 105:           </option>",
                "// Line 106:         </select>",
                "// vulnerable line: 107: </div>",
                "// Line 108:     );",
                "// Line 109:   }",
                "// Line 110: ",
                "// Line 111:   return (",
                "// vulnerable line: 112: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 113: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// Line 114:         Chat Model Selection",
                "// vulnerable line: 115: </label>",
                "// Line 116:       <select",
                "// Line 117:         name=\"LMStudioModelPref\"",
                "// vulnerable line: 118: required={true}",
                "// Line 119:         className=\"bg-zinc-900 border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"",
                "// Line 120:       >",
                "// Line 121:         {customModels.length > 0 && (",
                "// Line 122:           <optgroup label=\"Your loaded models\">",
                "// Line 123:             {customModels.map((model) => {",
                "// Line 124:               return (",
                "// Line 125:                 <option",
                "// Line 126:                   key={model.id}",
                "// Line 127:                   value={model.id}",
                "// Line 128:                   selected={settings.LMStudioModelPref === model.id}",
                "// Line 129:                 >",
                "// Line 130:                   {model.id}",
                "// Line 131:                 </option>",
                "// Line 132:               );",
                "// Line 133:             })}",
                "// Line 134:           </optgroup>",
                "// Line 135:         )}",
                "// Line 136:       </select>",
                "// vulnerable line: 137: </div>",
                "// Line 138:   );",
                "// Line 139: }"
            ]
        },
        {
            "filename_of_changes": "index.jsx",
            "code_language": "JavaScript",
            "number_of_lines_added_for_mitigation": "21",
            "number_of_lines_deleted_vulnerable_to_cve": "17",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 3: ",
                "// Line 4: export default function OllamaLLMOptions({ settings }) {",
                "// Line 5:   const [basePathValue, setBasePathValue] = useState(",
                "// Line 6:     settings?.OllamaLLMBasePath",
                "// Line 7:   );",
                "// Line 8:   const [basePath, setBasePath] = useState(settings?.OllamaLLMBasePath);",
                "// Line 9: ",
                "// Line 10:   return (",
                "// Line 11:     <div className=\"w-full flex flex-col gap-y-4\">",
                "// Line 12:       <div className=\"w-full flex items-center gap-4\">",
                "// vulnerable line: 13: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 14: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// Line 15:             Ollama Base URL",
                "// vulnerable line: 16: </label>",
                "// vulnerable line: 17: <input",
                "// Line 18:             type=\"url\"",
                "// Line 19:             name=\"OllamaLLMBasePath\"",
                "// vulnerable line: 20: className=\"bg-zinc-900 text-white placeholder:text-white/20 text-sm rounded-lg focus:border-white block w-full p-2.5\"",
                "// Line 21:             placeholder=\"http://127.0.0.1:11434\"",
                "// Line 22:             defaultValue={settings?.OllamaLLMBasePath}",
                "// vulnerable line: 23: required={true}",
                "// vulnerable line: 24: autoComplete=\"off\"",
                "// Line 25:             spellCheck={false}",
                "// Line 26:             onChange={(e) => setBasePathValue(e.target.value)}",
                "// Line 27:             onBlur={() => setBasePath(basePathValue)}",
                "// vulnerable line: 28: />",
                "// vulnerable line: 29: </div>",
                "// vulnerable line: 30: <OllamaLLMModelSelection settings={settings} basePath={basePath} />",
                "// vulnerable line: 31: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 32: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// vulnerable line: 33: Token context window",
                "// vulnerable line: 34: </label>",
                "// vulnerable line: 35: <input",
                "// vulnerable line: 36: type=\"number\"",
                "// vulnerable line: 37: name=\"OllamaLLMTokenLimit\"",
                "// vulnerable line: 38: className=\"bg-zinc-900 text-white placeholder:text-white/20 text-sm rounded-lg focus:border-white block w-full p-2.5\"",
                "// vulnerable line: 39: placeholder=\"4096\"",
                "// vulnerable line: 40: min={1}",
                "// vulnerable line: 41: onScroll={(e) => e.target.blur()}",
                "// vulnerable line: 42: defaultValue={settings?.OllamaLLMTokenLimit}",
                "// vulnerable line: 43: required={true}",
                "// vulnerable line: 44: autoComplete=\"off\"",
                "// vulnerable line: 45: />",
                "// vulnerable line: 46: </div>",
                "// vulnerable line: 47: </div>",
                "// vulnerable line: 48: </div>",
                "// Line 49:   );",
                "// Line 50: }",
                "// Line 51: ",
                "// Line 52: function OllamaLLMModelSelection({ settings, basePath = null }) {",
                "// Line 53:   const [customModels, setCustomModels] = useState([]);",
                "// Line 54:   const [loading, setLoading] = useState(true);",
                "// Line 55: ",
                "// Line 56:   useEffect(() => {",
                "// Line 57:     async function findCustomModels() {",
                "// Line 58:       if (!basePath) {",
                "// Line 63:       setLoading(true);",
                "// Line 64:       const { models } = await System.customModels(\"ollama\", null, basePath);",
                "// Line 65:       setCustomModels(models || []);",
                "// Line 66:       setLoading(false);",
                "// Line 67:     }",
                "// Line 68:     findCustomModels();",
                "// Line 69:   }, [basePath]);",
                "// Line 70: ",
                "// Line 71:   if (loading || customModels.length == 0) {",
                "// Line 72:     return (",
                "// vulnerable line: 73: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 74: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// Line 75:           Chat Model Selection",
                "// vulnerable line: 76: </label>",
                "// Line 77:         <select",
                "// Line 78:           name=\"OllamaLLMModelPref\"",
                "// Line 79:           disabled={true}",
                "// Line 80:           className=\"bg-zinc-900 border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"",
                "// Line 81:         >",
                "// Line 82:           <option disabled={true} selected={true}>",
                "// Line 83:             {!!basePath",
                "// Line 84:               ? \"-- loading available models --\"",
                "// Line 85:               : \"-- waiting for URL --\"}",
                "// Line 86:           </option>",
                "// Line 87:         </select>",
                "// vulnerable line: 88: </div>",
                "// Line 89:     );",
                "// Line 90:   }",
                "// Line 91: ",
                "// Line 92:   return (",
                "// vulnerable line: 93: <div className=\"flex flex-col w-60\">",
                "// vulnerable line: 94: <label className=\"text-white text-sm font-semibold block mb-4\">",
                "// Line 95:         Chat Model Selection",
                "// vulnerable line: 96: </label>",
                "// Line 97:       <select",
                "// Line 98:         name=\"OllamaLLMModelPref\"",
                "// vulnerable line: 99: required={true}",
                "// Line 100:         className=\"bg-zinc-900 border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"",
                "// Line 101:       >",
                "// Line 102:         {customModels.length > 0 && (",
                "// Line 103:           <optgroup label=\"Your loaded models\">",
                "// Line 104:             {customModels.map((model) => {",
                "// Line 105:               return (",
                "// Line 106:                 <option",
                "// Line 107:                   key={model.id}",
                "// Line 108:                   value={model.id}",
                "// Line 109:                   selected={settings.OllamaLLMModelPref === model.id}",
                "// Line 110:                 >",
                "// Line 111:                   {model.id}",
                "// Line 112:                 </option>",
                "// Line 113:               );",
                "// Line 114:             })}",
                "// Line 115:           </optgroup>",
                "// Line 116:         )}",
                "// Line 117:       </select>",
                "// vulnerable line: 118: </div>",
                "// Line 119:   );",
                "// Line 120: }"
            ]
        },
        {
            "filename_of_changes": "index.jsx",
            "code_language": "JavaScript",
            "number_of_lines_added_for_mitigation": "3",
            "number_of_lines_deleted_vulnerable_to_cve": "1",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 17:           className=\"bg-zinc-900 text-white placeholder:text-white/20 text-sm rounded-lg focus:border-white block w-full p-2.5\"",
                "// Line 18:           placeholder=\"OpenAI API Key\"",
                "// Line 19:           defaultValue={settings?.OpenAiKey ? \"*\".repeat(20) : \"\"}",
                "// Line 20:           required={true}",
                "// Line 21:           autoComplete=\"off\"",
                "// Line 22:           spellCheck={false}",
                "// Line 23:           onChange={(e) => setInputValue(e.target.value)}",
                "// Line 24:           onBlur={() => setOpenAIKey(inputValue)}",
                "// Line 25:         />",
                "// Line 26:       </div>",
                "// vulnerable line: 27: <OpenAIModelSelection settings={settings} apiKey={openAIKey} />",
                "// Line 28:     </div>",
                "// Line 29:   );",
                "// Line 30: }",
                "// Line 31: ",
                "// Line 32: function OpenAIModelSelection({ apiKey, settings }) {",
                "// Line 33:   const [customModels, setCustomModels] = useState([]);",
                "// Line 34:   const [loading, setLoading] = useState(true);",
                "// Line 35: ",
                "// Line 36:   useEffect(() => {",
                "// Line 37:     async function findCustomModels() {"
            ]
        },
        {
            "filename_of_changes": "updateENV.js",
            "code_language": "JavaScript",
            "number_of_lines_added_for_mitigation": "0",
            "number_of_lines_deleted_vulnerable_to_cve": "10",
            "Code_with_highlighted_vulnerability_lines": [
                "// Line 1: const KEY_MAPPING = {",
                "// Line 2:   LLMProvider: {",
                "// Line 3:     envKey: \"LLM_PROVIDER\",",
                "// Line 4:     checks: [isNotEmpty, supportedLLM],",
                "// vulnerable line: 5: postUpdate: [wipeWorkspaceModelPreference],",
                "// Line 6:   },",
                "// Line 7:   // OpenAI Settings",
                "// Line 8:   OpenAiKey: {",
                "// Line 9:     envKey: \"OPEN_AI_KEY\",",
                "// Line 10:     checks: [isNotEmpty, validOpenAIKey],",
                "// Line 11:   },",
                "// Line 12:   OpenAiModelPref: {",
                "// Line 13:     envKey: \"OPEN_MODEL_PREF\",",
                "// Line 14:     checks: [isNotEmpty],",
                "// Line 15:   },",
                "// Line 290:     checks: [requiresForceMode],",
                "// Line 291:   },",
                "// Line 292:   DisableTelemetry: {",
                "// Line 293:     envKey: \"DISABLE_TELEMETRY\",",
                "// Line 294:     checks: [],",
                "// Line 295:   },",
                "// Line 296: };",
                "// Line 297: ",
                "// Line 298: function isNotEmpty(input = \"\") {",
                "// Line 299:   return !input || input.length === 0 ? \"Value cannot be empty\" : null;",
                "// vulnerable line: 300: }",
                "// Line 301: ",
                "// Line 302: function nonZero(input = \"\") {",
                "// Line 303:   if (isNaN(Number(input))) return \"Value must be a number\";",
                "// Line 304:   return Number(input) <= 0 ? \"Value must be greater than zero\" : null;",
                "// vulnerable line: 305: }",
                "// Line 306: ",
                "// Line 307: function isValidURL(input = \"\") {",
                "// Line 308:   try {",
                "// Line 309:     new URL(input);",
                "// Line 310:     return null;",
                "// Line 311:   } catch (e) {",
                "// Line 312:     return \"URL is not a valid URL.\";",
                "// vulnerable line: 313: }",
                "// vulnerable line: 314: }",
                "// Line 315: ",
                "// Line 316: function validOpenAIKey(input = \"\") {",
                "// Line 317:   return input.startsWith(\"sk-\") ? null : \"OpenAI Key must start with sk-\";",
                "// vulnerable line: 318: }",
                "// Line 319: ",
                "// Line 320: function validAnthropicApiKey(input = \"\") {",
                "// Line 321:   return input.startsWith(\"sk-ant-\")",
                "// Line 322:     ? null",
                "// Line 323:     : \"Anthropic Key must start with sk-ant-\";",
                "// vulnerable line: 324: }",
                "// Line 325: ",
                "// Line 326: function validLLMExternalBasePath(input = \"\") {",
                "// Line 327:   try {",
                "// Line 328:     new URL(input);",
                "// Line 329:     if (!input.includes(\"v1\")) return \"URL must include /v1\";",
                "// Line 330:     if (input.split(\"\").slice(-1)?.[0] === \"/\")",
                "// Line 331:       return \"URL cannot end with a slash\";",
                "// Line 332:     return null;",
                "// Line 333:   } catch {",
                "// Line 334:     return \"Not a valid URL\";",
                "// vulnerable line: 335: }",
                "// vulnerable line: 336: }",
                "// Line 337: ",
                "// Line 338: function validOllamaLLMBasePath(input = \"\") {",
                "// Line 339:   try {",
                "// Line 340:     new URL(input);",
                "// Line 341:     if (input.split(\"\").slice(-1)?.[0] === \"/\")",
                "// Line 342:       return \"URL cannot end with a slash\";",
                "// Line 343:     return null;",
                "// Line 344:   } catch {",
                "// Line 345:     return \"Not a valid URL\";",
                "// vulnerable line: 346: }",
                "// vulnerable line: 347: }",
                "// Line 348: ",
                "// Line 349: function supportedLLM(input = \"\") {",
                "// Line 350:   const validSelection = [",
                "// Line 351:     \"openai\",",
                "// Line 352:     \"azure\",",
                "// Line 353:     \"anthropic\",",
                "// Line 354:     \"gemini\",",
                "// Line 355:     \"lmstudio\",",
                "// Line 356:     \"localai\",",
                "// Line 357:     \"ollama\",",
                "// Line 358:     \"native\",",
                "// Line 359:     \"togetherai\",",
                "// Line 360:     \"mistral\",",
                "// Line 361:     \"huggingface\",",
                "// Line 362:     \"perplexity\",",
                "// Line 363:     \"openrouter\",",
                "// Line 364:     \"groq\",",
                "// Line 365:   ].includes(input);",
                "// Line 366:   return validSelection ? null : `${input} is not a valid LLM provider.`;",
                "// vulnerable line: 367: }",
                "// Line 368: ",
                "// Line 369: function supportedTranscriptionProvider(input = \"\") {",
                "// Line 370:   const validSelection = [\"openai\", \"local\"].includes(input);",
                "// Line 371:   return validSelection",
                "// Line 372:     ? null",
                "// Line 373:     : `${input} is not a valid transcription model provider.`;",
                "// vulnerable line: 374: }",
                "// Line 375: ",
                "// Line 376: function validGeminiModel(input = \"\") {",
                "// Line 377:   const validModels = [\"gemini-pro\"];",
                "// Line 378:   return validModels.includes(input)",
                "// Line 379:     ? null",
                "// Line 380:     : `Invalid Model type. Must be one of ${validModels.join(\", \")}.`;",
                "// vulnerable line: 381: }",
                "// Line 382: ",
                "// Line 383: function validAnthropicModel(input = \"\") {",
                "// Line 384:   const validModels = [",
                "// Line 385:     \"claude-instant-1.2\",",
                "// Line 386:     \"claude-2.0\",",
                "// Line 387:     \"claude-2.1\",",
                "// Line 388:     \"claude-3-opus-20240229\",",
                "// Line 389:     \"claude-3-sonnet-20240229\",",
                "// Line 390:     \"claude-3-haiku-20240307\",",
                "// Line 391:   ];",
                "// Line 392:   return validModels.includes(input)",
                "// Line 393:     ? null",
                "// Line 394:     : `Invalid Model type. Must be one of ${validModels.join(\", \")}.`;",
                "// vulnerable line: 395: }",
                "// Line 396: ",
                "// Line 397: function supportedEmbeddingModel(input = \"\") {",
                "// Line 398:   const supported = [\"openai\", \"azure\", \"localai\", \"native\", \"ollama\"];",
                "// Line 399:   return supported.includes(input)",
                "// Line 400:     ? null",
                "// Line 401:     : `Invalid Embedding model type. Must be one of ${supported.join(\", \")}.`;",
                "// vulnerable line: 402: }",
                "// Line 403: ",
                "// Line 404: function supportedVectorDB(input = \"\") {",
                "// Line 405:   const supported = [",
                "// Line 406:     \"chroma\",",
                "// Line 407:     \"pinecone\",",
                "// Line 408:     \"lancedb\",",
                "// Line 409:     \"weaviate\",",
                "// Line 410:     \"qdrant\",",
                "// Line 411:     \"milvus\",",
                "// Line 412:     \"zilliz\",",
                "// Line 413:     \"astra\",",
                "// Line 414:   ];",
                "// Line 415:   return supported.includes(input)",
                "// Line 416:     ? null",
                "// Line 417:     : `Invalid VectorDB type. Must be one of ${supported.join(\", \")}.`;",
                "// vulnerable line: 418: }",
                "// Line 419: ",
                "// Line 420: function validChromaURL(input = \"\") {",
                "// Line 421:   return input.slice(-1) === \"/\"",
                "// Line 422:     ? `Chroma Instance URL should not end in a trailing slash.`",
                "// Line 423:     : null;",
                "// vulnerable line: 424: }",
                "// Line 425: ",
                "// Line 426: function validAzureURL(input = \"\") {",
                "// Line 427:   try {",
                "// Line 428:     new URL(input);",
                "// Line 429:     if (!input.includes(\"openai.azure.com\"))",
                "// Line 430:       return \"URL must include openai.azure.com\";",
                "// Line 431:     return null;",
                "// Line 432:   } catch {",
                "// Line 433:     return \"Not a valid URL\";",
                "// vulnerable line: 434: }",
                "// vulnerable line: 435: }",
                "// Line 436: ",
                "// Line 437: function validOpenAiTokenLimit(input = \"\") {",
                "// Line 438:   const tokenLimit = Number(input);",
                "// Line 439:   if (isNaN(tokenLimit)) return \"Token limit is not a number\";",
                "// Line 440:   if (![4_096, 16_384, 8_192, 32_768, 128_000].includes(tokenLimit))",
                "// Line 441:     return \"Invalid OpenAI token limit.\";",
                "// Line 442:   return null;",
                "// vulnerable line: 443: }",
                "// Line 444: ",
                "// Line 445: function requiresForceMode(_, forceModeEnabled = false) {",
                "// Line 446:   return forceModeEnabled === true ? null : \"Cannot set this setting.\";",
                "// vulnerable line: 447: }",
                "// Line 448: ",
                "// Line 449: function isDownloadedModel(input = \"\") {",
                "// Line 450:   const fs = require(\"fs\");",
                "// Line 451:   const path = require(\"path\");",
                "// Line 452:   const storageDir = path.resolve(",
                "// Line 453:     process.env.STORAGE_DIR",
                "// Line 454:       ? path.resolve(process.env.STORAGE_DIR, \"models\", \"downloaded\")",
                "// Line 455:       : path.resolve(__dirname, `../../storage/models/downloaded`)",
                "// Line 456:   );",
                "// Line 457:   if (!fs.existsSync(storageDir)) return false;",
                "// Line 458: ",
                "// Line 459:   const files = fs",
                "// Line 460:     .readdirSync(storageDir)",
                "// Line 461:     .filter((file) => file.includes(\".gguf\"));",
                "// Line 462:   return files.includes(input);",
                "// vulnerable line: 463: }",
                "// Line 464: ",
                "// Line 465: async function validDockerizedUrl(input = \"\") {",
                "// Line 466:   if (process.env.ANYTHING_LLM_RUNTIME !== \"docker\") return null;",
                "// Line 467: ",
                "// Line 468:   try {",
                "// Line 469:     const { isPortInUse, getLocalHosts } = require(\"./portAvailabilityChecker\");",
                "// Line 470:     const localInterfaces = getLocalHosts();",
                "// Line 471:     const url = new URL(input);",
                "// Line 472:     const hostname = url.hostname.toLowerCase();",
                "// Line 473:     const port = parseInt(url.port, 10);",
                "// Line 475:     // If not a loopback, skip this check.",
                "// Line 476:     if (!localInterfaces.includes(hostname)) return null;",
                "// Line 477:     if (isNaN(port)) return \"Invalid URL: Port is not specified or invalid\";",
                "// Line 478: ",
                "// Line 479:     const isPortAvailableFromDocker = await isPortInUse(port, hostname);",
                "// Line 480:     if (isPortAvailableFromDocker)",
                "// Line 481:       return \"Port is not running a reachable service on loopback address from inside the AnythingLLM container. Please use host.docker.internal (for linux use 172.17.0.1), a real machine ip, or domain to connect to your service.\";",
                "// Line 482:   } catch (error) {",
                "// Line 483:     console.error(error.message);",
                "// Line 484:     return \"An error occurred while validating the URL\";",
                "// vulnerable line: 485: }",
                "// Line 486: ",
                "// Line 487:   return null;",
                "// vulnerable line: 488: }",
                "// Line 489: ",
                "// Line 490: function validHuggingFaceEndpoint(input = \"\") {",
                "// Line 491:   return input.slice(-6) !== \".cloud\"",
                "// Line 492:     ? `Your HF Endpoint should end in \".cloud\"`",
                "// Line 493:     : null;",
                "// vulnerable line: 494: }",
                "// Line 495: ",
                "// vulnerable line: 496: // If the LLMProvider has changed we need to reset all workspace model preferences to",
                "// vulnerable line: 497: // null since the provider<>model name combination will be invalid for whatever the new",
                "// vulnerable line: 498: // provider is.",
                "// vulnerable line: 499: async function wipeWorkspaceModelPreference(key, prev, next) {",
                "// vulnerable line: 500: if (prev === next) return;",
                "// vulnerable line: 501: const { Workspace } = require(\"../../models/workspace\");",
                "// vulnerable line: 502: await Workspace.resetWorkspaceChatModels();",
                "// vulnerable line: 503: }",
                "// Line 504: ",
                "// Line 505: // This will force update .env variables which for any which reason were not able to be parsed or",
                "// Line 506: // read from an ENV file as this seems to be a complicating step for many so allowing people to write",
                "// Line 507: // to the process will at least alleviate that issue. It does not perform comprehensive validity checks or sanity checks",
                "// Line 508: // and is simply for debugging when the .env not found issue many come across.",
                "// Line 509: async function updateENV(newENVs = {}, force = false, userId = null) {",
                "// Line 510:   let error = \"\";",
                "// Line 511:   const validKeys = Object.keys(KEY_MAPPING);",
                "// Line 512:   const ENV_KEYS = Object.keys(newENVs).filter(",
                "// Line 513:     (key) => validKeys.includes(key) && !newENVs[key].includes(\"******\") // strip out answers where the value is all asterisks",
                "// Line 517:   for (const key of ENV_KEYS) {",
                "// Line 518:     const { envKey, checks, postUpdate = [] } = KEY_MAPPING[key];",
                "// Line 519:     const prevValue = process.env[envKey];",
                "// Line 520:     const nextValue = newENVs[key];",
                "// Line 521: ",
                "// Line 522:     const errors = await executeValidationChecks(checks, nextValue, force);",
                "// Line 523:     if (errors.length > 0) {",
                "// Line 524:       error += errors.join(\"",
                "// Line 525: \");",
                "// Line 526:       break;",
                "// vulnerable line: 527: }",
                "// Line 528: ",
                "// Line 529:     newValues[key] = nextValue;",
                "// Line 530:     process.env[envKey] = nextValue;",
                "// Line 531: ",
                "// Line 532:     for (const postUpdateFunc of postUpdate)",
                "// Line 533:       await postUpdateFunc(key, prevValue, nextValue);",
                "// vulnerable line: 534: }",
                "// Line 535: ",
                "// Line 536:   await logChangesToEventLog(newValues, userId);",
                "// Line 537:   return { newValues, error: error?.length > 0 ? error : false };",
                "// vulnerable line: 538: }",
                "// Line 539: ",
                "// Line 540: async function executeValidationChecks(checks, value, force) {",
                "// Line 541:   const results = await Promise.all(",
                "// Line 542:     checks.map((validator) => validator(value, force))",
                "// Line 543:   );",
                "// Line 544:   return results.filter((err) => typeof err === \"string\");",
                "// vulnerable line: 545: }",
                "// Line 546: ",
                "// Line 547: async function logChangesToEventLog(newValues = {}, userId = null) {",
                "// Line 548:   const { EventLogs } = require(\"../../models/eventLogs\");",
                "// Line 549:   const eventMapping = {",
                "// Line 550:     LLMProvider: \"update_llm_provider\",",
                "// Line 551:     EmbeddingEngine: \"update_embedding_engine\",",
                "// Line 552:     VectorDB: \"update_vector_db\",",
                "// Line 553:   };",
                "// Line 554: ",
                "// Line 555:   for (const [key, eventName] of Object.entries(eventMapping)) {",
                "// Line 556:     if (!newValues.hasOwnProperty(key)) continue;",
                "// Line 557:     await EventLogs.logEvent(eventName, {}, userId);",
                "// vulnerable line: 558: }",
                "// Line 559:   return;",
                "// vulnerable line: 560: }",
                "// Line 561: ",
                "// Line 562: async function dumpENV() {",
                "// Line 563:   const fs = require(\"fs\");",
                "// Line 564:   const path = require(\"path\");",
                "// Line 565: ",
                "// Line 566:   const frozenEnvs = {};",
                "// Line 567:   const protectedKeys = [",
                "// Line 568:     ...Object.values(KEY_MAPPING).map((values) => values.envKey),",
                "// Line 569:     \"STORAGE_DIR\",",
                "// Line 570:     \"SERVER_PORT\",",
                "// Line 592: ",
                "// Line 593: ",
                "// Line 594: ",
                "// Line 595:   ᠎ - ",
                "// Line 596: ",
                "// Line 597:   　\"'`#]/;",
                "// Line 598:     const firstOffendingCharIndex = value.search(offendingChars);",
                "// Line 599:     if (firstOffendingCharIndex === -1) return value;",
                "// Line 600: ",
                "// Line 601:     return value.substring(0, firstOffendingCharIndex);",
                "// vulnerable line: 602: }",
                "// Line 603: ",
                "// Line 604:   for (const key of protectedKeys) {",
                "// Line 605:     const envValue = process.env?.[key] || null;",
                "// Line 606:     if (!envValue) continue;",
                "// Line 607:     frozenEnvs[key] = process.env?.[key] || null;",
                "// vulnerable line: 608: }",
                "// Line 609: ",
                "// Line 610:   var envResult = `# Auto-dump ENV from system call on ${new Date().toTimeString()}",
                "// Line 611: `;",
                "// Line 612:   envResult += Object.entries(frozenEnvs)",
                "// Line 613:     .map(([key, value]) => `${key}='${sanitizeValue(value)}'`)",
                "// Line 614:     .join(\"",
                "// Line 615: \");",
                "// Line 616: ",
                "// Line 617:   const envPath = path.join(__dirname, \"../../.env\");",
                "// Line 618:   fs.writeFileSync(envPath, envResult, { encoding: \"utf8\", flag: \"w\" });",
                "// Line 619:   return true;",
                "// vulnerable line: 620: }",
                "// Line 621: ",
                "// Line 622: module.exports = {",
                "// Line 623:   dumpENV,",
                "// Line 624:   updateENV,",
                "// Line 625: };"
            ]
        }
    ]
}