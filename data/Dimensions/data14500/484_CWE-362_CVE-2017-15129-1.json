{
    "cve_id": "CVE-2017-15129",
    "cve_description": "A use-after-free vulnerability was found in network namespaces code affecting the Linux kernel before 4.14.11. The function get_net_ns_by_id() in net/core/net_namespace.c does not check for the net::count value after it has found a peer network in netns_ids idr, which could lead to double free and memory corruption. This vulnerability could allow an unprivileged local user to induce kernel memory corruption on the system, leading to a crash. Due to the nature of the flaw, privilege escalation cannot be fully ruled out, although it is thought to be unlikely.",
    "cve_publish_date": "2018-01-09",
    "cwe_id": "CWE-362",
    "cwe_name": "Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition')",
    "cwe_description": "The product contains a code sequence that can run concurrently with other code, and the code sequence requires temporary, exclusive access to a shared resource, but a timing window exists in which the shared resource can be modified by another code sequence that is operating concurrently.",
    "commit_message": "net: Fix double free and memory corruption in get_net_ns_by_id()\n\n(I can trivially verify that that idr_remove in cleanup_net happens\n after the network namespace count has dropped to zero --EWB)\n\nFunction get_net_ns_by_id() does not check for net::count\nafter it has found a peer in netns_ids idr.\n\nIt may dereference a peer, after its count has already been\nfinaly decremented. This leads to double free and memory\ncorruption:\n\nput_net(peer)                                   rtnl_lock()\natomic_dec_and_test(&peer->count) [count=0]     ...\n__put_net(peer)                                 get_net_ns_by_id(net, id)\n  spin_lock(&cleanup_list_lock)\n  list_add(&net->cleanup_list, &cleanup_list)\n  spin_unlock(&cleanup_list_lock)\nqueue_work()                                      peer = idr_find(&net->netns_ids, id)\n  |                                               get_net(peer) [count=1]\n  |                                               ...\n  |                                               (use after final put)\n  v                                               ...\n  cleanup_net()                                   ...\n    spin_lock(&cleanup_list_lock)                 ...\n    list_replace_init(&cleanup_list, ..)          ...\n    spin_unlock(&cleanup_list_lock)               ...\n    ...                                           ...\n    ...                                           put_net(peer)\n    ...                                             atomic_dec_and_test(&peer->count) [count=0]\n    ...                                               spin_lock(&cleanup_list_lock)\n    ...                                               list_add(&net->cleanup_list, &cleanup_list)\n    ...                                               spin_unlock(&cleanup_list_lock)\n    ...                                             queue_work()\n    ...                                           rtnl_unlock()\n    rtnl_lock()                                   ...\n    for_each_net(tmp) {                           ...\n      id = __peernet2id(tmp, peer)                ...\n      spin_lock_irq(&tmp->nsid_lock)              ...\n      idr_remove(&tmp->netns_ids, id)             ...\n      ...                                         ...\n      net_drop_ns()                               ...\n\tnet_free(peer)                            ...\n    }                                             ...\n  |\n  v\n  cleanup_net()\n    ...\n    (Second free of peer)\n\nAlso, put_net() on the right cpu may reorder with left's cpu\nlist_replace_init(&cleanup_list, ..), and then cleanup_list\nwill be corrupted.\n\nSince cleanup_net() is executed in worker thread, while\nput_net(peer) can happen everywhere, there should be\nenough time for concurrent get_net_ns_by_id() to pick\nthe peer up, and the race does not seem to be unlikely.\nThe patch fixes the problem in standard way.\n\n(Also, there is possible problem in peernet2id_alloc(), which requires\ncheck for net::count under nsid_lock and maybe_get_net(peer), but\nin current stable kernel it's used under rtnl_lock() and it has to be\nsafe. Openswitch begun to use peernet2id_alloc(), and possibly it should\nbe fixed too. While this is not in stable kernel yet, so I'll send\na separate message to netdev@ later).\n\nCc: Nicolas Dichtel <nicolas.dichtel@6wind.com>\nSigned-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>\nFixes: 0c7aecd4bde4 \"netns: add rtnl cmd to add and get peer netns ids\"\nReviewed-by: Andrey Ryabinin <aryabinin@virtuozzo.com>\nReviewed-by: \"Eric W. Biederman\" <ebiederm@xmission.com>\nSigned-off-by: Eric W. Biederman <ebiederm@xmission.com>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nAcked-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
    "type_of_change": "Modification",
    "filename_of_changes": "net_namespace.c",
    "code_language": "C",
    "number_of_lines_added_for_mitigation": "1",
    "number_of_lines_deleted_vulnerable_to_cve": "1",
    "vulnerable_lines": [
        "// Line_Reference 270: \t\tget_net(peer);"
    ]
}
