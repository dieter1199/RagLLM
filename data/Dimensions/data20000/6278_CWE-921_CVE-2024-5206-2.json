{
    "cve_id": "CVE-2024-5206",
    "cve_description": "A sensitive data leakage vulnerability was identified in scikit-learn's TfidfVectorizer, specifically in versions up to and including 1.4.1.post1, which was fixed in version 1.5.0. The vulnerability arises from the unexpected storage of all tokens present in the training data within the `stop_words_` attribute, rather than only storing the subset of tokens required for the TF-IDF technique to function. This behavior leads to the potential leakage of sensitive information, as the `stop_words_` attribute could contain tokens that were meant to be discarded and not stored, such as passwords or keys. The impact of this vulnerability varies based on the nature of the data being processed by the vectorizer.",
    "cve_publish_date": "2024-06-06",
    "cwe_id": "CWE-921",
    "cwe_name": "Storage of Sensitive Data in a Mechanism without Access Control",
    "cwe_description": "The product stores sensitive information in a file system or device that does not have built-in access control.",
    "commit_message": "FIX remove the computed stop_words_ attribute of text vectorizer (#28823)",
    "type_of_change": "Modification",
    "filename_of_changes": "text.py",
    "code_language": "Python",
    "number_of_lines_added_for_mitigation": "2",
    "number_of_lines_deleted_vulnerable_to_cve": "34",
    "vulnerable_lines": [
        "// Line_Reference 1082:     stop_words_ : set",
        "// Line_Reference 1083:         Terms that were ignored because they either:",
        "// Line_Reference 1084: ",
        "// Line_Reference 1085:           - occurred in too many documents (`max_df`)",
        "// Line_Reference 1086:           - occurred in too few documents (`min_df`)",
        "// Line_Reference 1087:           - were cut off by feature selection (`max_features`).",
        "// Line_Reference 1088: ",
        "// Line_Reference 1089:         This is only available if no vocabulary was given.",
        "// Line_Reference 1090: ",
        "// Line_Reference 1099:     Notes",
        "// Line_Reference 1100:     -----",
        "// Line_Reference 1101:     The ``stop_words_`` attribute can get large and increase the model size",
        "// Line_Reference 1102:     when pickling. This attribute is provided only for introspection and can",
        "// Line_Reference 1103:     be safely removed using delattr or set to None before pickling.",
        "// Line_Reference 1104: ",
        "// Line_Reference 1243:         removed_terms = set()",
        "// Line_Reference 1249:                 removed_terms.add(term)",
        "// Line_Reference 1255:         return X[:, kept_indices], removed_terms",
        "// Line_Reference 1400:             X, self.stop_words_ = self._limit_features(",
        "// Line_Reference 1914:     stop_words_ : set",
        "// Line_Reference 1915:         Terms that were ignored because they either:",
        "// Line_Reference 1916: ",
        "// Line_Reference 1917:           - occurred in too many documents (`max_df`)",
        "// Line_Reference 1918:           - occurred in too few documents (`min_df`)",
        "// Line_Reference 1919:           - were cut off by feature selection (`max_features`).",
        "// Line_Reference 1920: ",
        "// Line_Reference 1921:         This is only available if no vocabulary was given.",
        "// Line_Reference 1922: ",
        "// Line_Reference 1930:     Notes",
        "// Line_Reference 1931:     -----",
        "// Line_Reference 1932:     The ``stop_words_`` attribute can get large and increase the model size",
        "// Line_Reference 1933:     when pickling. This attribute is provided only for introspection and can",
        "// Line_Reference 1934:     be safely removed using delattr or set to None before pickling.",
        "// Line_Reference 1935: "
    ]
}
