{
    "cve_id": "CVE-2020-15211",
    "cve_description": "In TensorFlow Lite before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1, saved models in the flatbuffer format use a double indexing scheme: a model has a set of subgraphs, each subgraph has a set of operators and each operator has a set of input/output tensors. The flatbuffer format uses indices for the tensors, indexing into an array of tensors that is owned by the subgraph. This results in a pattern of double array indexing when trying to get the data of each tensor. However, some operators can have some tensors be optional. To handle this scenario, the flatbuffer model uses a negative `-1` value as index for these tensors. This results in special casing during validation at model loading time. Unfortunately, this means that the `-1` index is a valid tensor index for any operator, including those that don't expect optional inputs and including for output tensors. Thus, this allows writing and reading from outside the bounds of heap allocated arrays, although only at a specific offset from the start of these arrays. This results in both read and write gadgets, albeit very limited in scope. The issue is patched in several commits (46d5b0852, 00302787b7, e11f5558, cd31fd0ce, 1970c21, and fff2c83), and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1. A potential workaround would be to add a custom `Verifier` to the model loading code to ensure that only operators which accept optional inputs use the `-1` special value and only for the tensors that they expect to be optional. Since this allow-list type approach is erro-prone, we advise upgrading to the patched code.",
    "cve_publish_date": "2020-09-25",
    "cwe_id": "CWE-125",
    "cwe_name": "Out-of-bounds Read",
    "cwe_description": "The product reads data past the end, or before the beginning, of the intended buffer.",
    "commit_message": "[tflite]: Insert `nullptr` checks when obtaining tensors.\n\nAs part of ongoing refactoring, `tflite::GetInput`, `tflite::GetOutput`, `tflite::GetTemporary` and `tflite::GetIntermediates` will return `nullptr` in some cases. Hence, we insert the `nullptr` checks on all usages.\n\nWe also insert `nullptr` checks on usages of `tflite::GetVariableInput` and `tflite::GetOptionalInputTensor` but only in the cases where there is no obvious check that `nullptr` is acceptable (that is, we only insert the check for the output of these two functions if the tensor is accessed as if it is always not `nullptr`).\n\nPiperOrigin-RevId: 332521299\nChange-Id: I29af455bcb48d0b92e58132d951a3badbd772d56",
    "type_of_change": "Modification",
    "filename_of_changes": "unidirectional_sequence_lstm.cc",
    "code_language": "C++",
    "number_of_lines_added_for_mitigation": "161",
    "number_of_lines_deleted_vulnerable_to_cve": "72",
    "vulnerable_lines": [
        "// Line_Reference 91:   const TfLiteTensor* input_to_forget_weights =",
        "// Line_Reference 92:       GetInput(context, node, lstm::full::kInputToForgetWeightsTensor);",
        "// Line_Reference 97:   const TfLiteTensor* input_to_cell_weights =",
        "// Line_Reference 98:       GetInput(context, node, lstm::full::kInputToCellWeightsTensor);",
        "// Line_Reference 113:   const TfLiteTensor* recurrent_to_forget_weights =",
        "// Line_Reference 114:       GetInput(context, node, lstm::full::kRecurrentToForgetWeightsTensor);",
        "// Line_Reference 121:   const TfLiteTensor* recurrent_to_cell_weights =",
        "// Line_Reference 122:       GetInput(context, node, lstm::full::kRecurrentToCellWeightsTensor);",
        "// Line_Reference 179:   const TfLiteTensor* forget_gate_bias =",
        "// Line_Reference 180:       GetInput(context, node, lstm::full::kForgetGateBiasTensor);",
        "// Line_Reference 184:   const TfLiteTensor* cell_gate_bias =",
        "// Line_Reference 185:       GetInput(context, node, lstm::full::kCellGateBiasTensor);",
        "// Line_Reference 189:   const TfLiteTensor* output_gate_bias =",
        "// Line_Reference 190:       GetInput(context, node, lstm::full::kOutputGateBiasTensor);",
        "// Line_Reference 232:     const TfLiteTensor* forget_layer_norm_coefficients =",
        "// Line_Reference 233:         GetInput(context, node, lstm::full::kForgetLayerNormCoefficientsTensor);",
        "// Line_Reference 234:     TF_LITE_ENSURE(context, forget_layer_norm_coefficients != nullptr);",
        "// Line_Reference 241:     const TfLiteTensor* cell_layer_norm_coefficients =",
        "// Line_Reference 242:         GetInput(context, node, lstm::full::kCellLayerNormCoefficientsTensor);",
        "// Line_Reference 243:     TF_LITE_ENSURE(context, cell_layer_norm_coefficients != nullptr);",
        "// Line_Reference 250:     const TfLiteTensor* output_layer_norm_coefficients =",
        "// Line_Reference 251:         GetInput(context, node, lstm::full::kOutputLayerNormCoefficientsTensor);",
        "// Line_Reference 252:     TF_LITE_ENSURE(context, output_layer_norm_coefficients != nullptr);",
        "// Line_Reference 294:   const TfLiteTensor* input = GetInput(context, node, lstm::full::kInputTensor);",
        "// Line_Reference 304:   const TfLiteTensor* input_to_output_weights =",
        "// Line_Reference 305:       GetInput(context, node, lstm::full::kInputToOutputWeightsTensor);",
        "// Line_Reference 310:   const TfLiteTensor* recurrent_to_output_weights =",
        "// Line_Reference 311:       GetInput(context, node, lstm::full::kRecurrentToOutputWeightsTensor);",
        "// Line_Reference 323:   TfLiteTensor* output = GetOutput(context, node, lstm::full::kOutputTensor);",
        "// Line_Reference 354:   TfLiteTensor* scratch_buffer = GetTemporary(context, node, kScratchBuffer);",
        "// Line_Reference 379:     TfLiteTensor* input_quantized =",
        "// Line_Reference 380:         GetTemporary(context, node, kInputQuantized);",
        "// Line_Reference 390:     TfLiteTensor* output_state_quantized =",
        "// Line_Reference 391:         GetTemporary(context, node, kOutputStateQuantized);",
        "// Line_Reference 404:     TfLiteTensor* cell_state_quantized =",
        "// Line_Reference 405:         GetTemporary(context, node, kCellStateQuantized);",
        "// Line_Reference 423:     TfLiteTensor* input_sf = GetTemporary(context, node, kInputScalingFactors);",
        "// Line_Reference 435:     TfLiteTensor* output_state_sf =",
        "// Line_Reference 436:         GetTemporary(context, node, kOutputStateScalingFactors);",
        "// Line_Reference 447:     TfLiteTensor* prod_scaling_factors =",
        "// Line_Reference 448:         GetTemporary(context, node, kProductScalingFactors);",
        "// Line_Reference 464:     TfLiteTensor* recovered_cell_weights =",
        "// Line_Reference 465:         GetTemporary(context, node, kRecoveredCellWeights);",
        "// Line_Reference 481:     TfLiteTensor* accum_scratch = GetTemporary(context, node, kAccumScratch);",
        "// Line_Reference 495:     TfLiteTensor* input_zp = GetTemporary(context, node, kInputZeroPoints);",
        "// Line_Reference 506:     TfLiteTensor* output_state_zp =",
        "// Line_Reference 507:         GetTemporary(context, node, kOutputStateZeroPoints);",
        "// Line_Reference 517:     TfLiteTensor* row_sums = GetTemporary(context, node, kRowSums);",
        "// Line_Reference 545:   const TfLiteTensor* input = GetInput(context, node, lstm::full::kInputTensor);",
        "// Line_Reference 549:   const TfLiteTensor* input_to_forget_weights =",
        "// Line_Reference 550:       GetInput(context, node, lstm::full::kInputToForgetWeightsTensor);",
        "// Line_Reference 551:   const TfLiteTensor* input_to_cell_weights =",
        "// Line_Reference 552:       GetInput(context, node, lstm::full::kInputToCellWeightsTensor);",
        "// Line_Reference 553:   const TfLiteTensor* input_to_output_weights =",
        "// Line_Reference 554:       GetInput(context, node, lstm::full::kInputToOutputWeightsTensor);",
        "// Line_Reference 558:   const TfLiteTensor* recurrent_to_forget_weights =",
        "// Line_Reference 559:       GetInput(context, node, lstm::full::kRecurrentToForgetWeightsTensor);",
        "// Line_Reference 560:   const TfLiteTensor* recurrent_to_cell_weights =",
        "// Line_Reference 561:       GetInput(context, node, lstm::full::kRecurrentToCellWeightsTensor);",
        "// Line_Reference 562:   const TfLiteTensor* recurrent_to_output_weights =",
        "// Line_Reference 563:       GetInput(context, node, lstm::full::kRecurrentToOutputWeightsTensor);",
        "// Line_Reference 574:   const TfLiteTensor* forget_gate_bias =",
        "// Line_Reference 575:       GetInput(context, node, lstm::full::kForgetGateBiasTensor);",
        "// Line_Reference 576:   const TfLiteTensor* cell_gate_bias =",
        "// Line_Reference 577:       GetInput(context, node, lstm::full::kCellGateBiasTensor);",
        "// Line_Reference 578:   const TfLiteTensor* output_gate_bias =",
        "// Line_Reference 579:       GetInput(context, node, lstm::full::kOutputGateBiasTensor);",
        "// Line_Reference 587:   TfLiteTensor* scratch_buffer = GetTemporary(context, node, kScratchBuffer);",
        "// Line_Reference 591:   TF_LITE_ENSURE(context, output_state != nullptr);",
        "// Line_Reference 594:   TF_LITE_ENSURE(context, cell_state != nullptr);",
        "// Line_Reference 617:   TfLiteTensor* output = GetOutput(context, node, lstm::full::kOutputTensor);",
        "// Line_Reference 650:       TfLiteTensor* row_sums = GetTemporary(context, node, kRowSums);"
    ]
}
