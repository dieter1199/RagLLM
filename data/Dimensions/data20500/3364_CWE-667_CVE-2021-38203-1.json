{
    "cve_id": "CVE-2021-38203",
    "cve_description": "btrfs in the Linux kernel before 5.13.4 allows attackers to cause a denial of service (deadlock) via processes that trigger allocation of new system chunks during times when there is a shortage of free space in the system space_info.",
    "cve_publish_date": "2021-08-08",
    "cwe_id": "CWE-667",
    "cwe_name": "Improper Locking",
    "cwe_description": "The product does not properly acquire or release a lock on a resource, leading to unexpected resource state changes and behaviors.",
    "commit_message": "btrfs: fix deadlock with concurrent chunk allocations involving system chunks\n\nWhen a task attempting to allocate a new chunk verifies that there is not\ncurrently enough free space in the system space_info and there is another\ntask that allocated a new system chunk but it did not finish yet the\ncreation of the respective block group, it waits for that other task to\nfinish creating the block group. This is to avoid exhaustion of the system\nchunk array in the superblock, which is limited, when we have a thundering\nherd of tasks allocating new chunks. This problem was described and fixed\nby commit eafa4fd0ad0607 (\"btrfs: fix exhaustion of the system chunk array\ndue to concurrent allocations\").\n\nHowever there are two very similar scenarios where this can lead to a\ndeadlock:\n\n1) Task B allocated a new system chunk and task A is waiting on task B\n   to finish creation of the respective system block group. However before\n   task B ends its transaction handle and finishes the creation of the\n   system block group, it attempts to allocate another chunk (like a data\n   chunk for an fallocate operation for a very large range). Task B will\n   be unable to progress and allocate the new chunk, because task A set\n   space_info->chunk_alloc to 1 and therefore it loops at\n   btrfs_chunk_alloc() waiting for task A to finish its chunk allocation\n   and set space_info->chunk_alloc to 0, but task A is waiting on task B\n   to finish creation of the new system block group, therefore resulting\n   in a deadlock;\n\n2) Task B allocated a new system chunk and task A is waiting on task B to\n   finish creation of the respective system block group. By the time that\n   task B enter the final phase of block group allocation, which happens\n   at btrfs_create_pending_block_groups(), when it modifies the extent\n   tree, the device tree or the chunk tree to insert the items for some\n   new block group, it needs to allocate a new chunk, so it ends up at\n   btrfs_chunk_alloc() and keeps looping there because task A has set\n   space_info->chunk_alloc to 1, but task A is waiting for task B to\n   finish creation of the new system block group and release the reserved\n   system space, therefore resulting in a deadlock.\n\nIn short, the problem is if a task B needs to allocate a new chunk after\nit previously allocated a new system chunk and if another task A is\ncurrently waiting for task B to complete the allocation of the new system\nchunk.\n\nUnfortunately this deadlock scenario introduced by the previous fix for\nthe system chunk array exhaustion problem does not have a simple and short\nfix, and requires a big change to rework the chunk allocation code so that\nchunk btree updates are all made in the first phase of chunk allocation.\nAnd since this deadlock regression is being frequently hit on zoned\nfilesystems and the system chunk array exhaustion problem is triggered\nin more extreme cases (originally observed on PowerPC with a node size\nof 64K when running the fallocate tests from stress-ng), revert the\nchanges from that commit. The next patch in the series, with a subject\nof \"btrfs: rework chunk allocation to avoid exhaustion of the system\nchunk array\" does the necessary changes to fix the system chunk array\nexhaustion problem.\n\nReported-by: Naohiro Aota <naohiro.aota@wdc.com>\nLink: https://lore.kernel.org/linux-btrfs/20210621015922.ewgbffxuawia7liz@naota-xeon/\nFixes: eafa4fd0ad0607 (\"btrfs: fix exhaustion of the system chunk array due to concurrent allocations\")\nCC: stable@vger.kernel.org # 5.12+\nTested-by: Shin'ichiro Kawasaki <shinichiro.kawasaki@wdc.com>\nTested-by: Naohiro Aota <naohiro.aota@wdc.com>\nSigned-off-by: Filipe Manana <fdmanana@suse.com>\nTested-by: David Sterba <dsterba@suse.com>\nSigned-off-by: David Sterba <dsterba@suse.com>",
    "type_of_change": "Modification",
    "filename_of_changes": "block-group.c",
    "code_language": "C",
    "number_of_lines_added_for_mitigation": "1",
    "number_of_lines_deleted_vulnerable_to_cve": "57",
    "vulnerable_lines": [
        "// Line_Reference 3380: \tstruct btrfs_transaction *cur_trans = trans->transaction;",
        "// Line_Reference 3395: again:",
        "// Line_Reference 3414: \t\tu64 reserved = atomic64_read(&cur_trans->chunk_bytes_reserved);",
        "// Line_Reference 3415: ",
        "// Line_Reference 3416: \t\t/*",
        "// Line_Reference 3417: \t\t * If there's not available space for the chunk tree (system",
        "// Line_Reference 3418: \t\t * space) and there are other tasks that reserved space for",
        "// Line_Reference 3419: \t\t * creating a new system block group, wait for them to complete",
        "// Line_Reference 3420: \t\t * the creation of their system block group and release excess",
        "// Line_Reference 3421: \t\t * reserved space. We do this because:",
        "// Line_Reference 3422: \t\t *",
        "// Line_Reference 3423: \t\t * *) We can end up allocating more system chunks than necessary",
        "// Line_Reference 3424: \t\t *    when there are multiple tasks that are concurrently",
        "// Line_Reference 3425: \t\t *    allocating block groups, which can lead to exhaustion of",
        "// Line_Reference 3426: \t\t *    the system array in the superblock;",
        "// Line_Reference 3427: \t\t *",
        "// Line_Reference 3428: \t\t * *) If we allocate extra and unnecessary system block groups,",
        "// Line_Reference 3429: \t\t *    despite being empty for a long time, and possibly forever,",
        "// Line_Reference 3430: \t\t *    they end not being added to the list of unused block groups",
        "// Line_Reference 3431: \t\t *    because that typically happens only when deallocating the",
        "// Line_Reference 3432: \t\t *    last extent from a block group - which never happens since",
        "// Line_Reference 3433: \t\t *    we never allocate from them in the first place. The few",
        "// Line_Reference 3434: \t\t *    exceptions are when mounting a filesystem or running scrub,",
        "// Line_Reference 3435: \t\t *    which add unused block groups to the list of unused block",
        "// Line_Reference 3436: \t\t *    groups, to be deleted by the cleaner kthread.",
        "// Line_Reference 3437: \t\t *    And even when they are added to the list of unused block",
        "// Line_Reference 3438: \t\t *    groups, it can take a long time until they get deleted,",
        "// Line_Reference 3439: \t\t *    since the cleaner kthread might be sleeping or busy with",
        "// Line_Reference 3440: \t\t *    other work (deleting subvolumes, running delayed iputs,",
        "// Line_Reference 3441: \t\t *    defrag scheduling, etc);",
        "// Line_Reference 3442: \t\t *",
        "// Line_Reference 3443: \t\t * This is rare in practice, but can happen when too many tasks",
        "// Line_Reference 3444: \t\t * are allocating blocks groups in parallel (via fallocate())",
        "// Line_Reference 3445: \t\t * and before the one that reserved space for a new system block",
        "// Line_Reference 3446: \t\t * group finishes the block group creation and releases the space",
        "// Line_Reference 3447: \t\t * reserved in excess (at btrfs_create_pending_block_groups()),",
        "// Line_Reference 3448: \t\t * other tasks end up here and see free system space temporarily",
        "// Line_Reference 3449: \t\t * not enough for updating the chunk tree.",
        "// Line_Reference 3450: \t\t *",
        "// Line_Reference 3451: \t\t * We unlock the chunk mutex before waiting for such tasks and",
        "// Line_Reference 3452: \t\t * lock it again after the wait, otherwise we would deadlock.",
        "// Line_Reference 3453: \t\t * It is safe to do so because allocating a system chunk is the",
        "// Line_Reference 3454: \t\t * first thing done while allocating a new block group.",
        "// Line_Reference 3455: \t\t */",
        "// Line_Reference 3456: \t\tif (reserved > trans->chunk_bytes_reserved) {",
        "// Line_Reference 3457: \t\t\tconst u64 min_needed = reserved - thresh;",
        "// Line_Reference 3458: ",
        "// Line_Reference 3459: \t\t\tmutex_unlock(&fs_info->chunk_mutex);",
        "// Line_Reference 3460: \t\t\twait_event(cur_trans->chunk_reserve_wait,",
        "// Line_Reference 3461: \t\t\t   atomic64_read(&cur_trans->chunk_bytes_reserved) <=",
        "// Line_Reference 3462: \t\t\t   min_needed);",
        "// Line_Reference 3463: \t\t\tmutex_lock(&fs_info->chunk_mutex);",
        "// Line_Reference 3464: \t\t\tgoto again;",
        "// Line_Reference 3465: \t\t}",
        "// Line_Reference 3480: \t\tif (!ret) {",
        "// Line_Reference 3481: \t\t\tatomic64_add(thresh, &cur_trans->chunk_bytes_reserved);",
        "// Line_Reference 3483: \t\t}"
    ]
}
