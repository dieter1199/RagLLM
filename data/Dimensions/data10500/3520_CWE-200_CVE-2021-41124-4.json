{
    "cve_id": "CVE-2021-41124",
    "cve_description": "Scrapy-splash is a library which provides Scrapy and JavaScript integration. In affected versions users who use [`HttpAuthMiddleware`](http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth) (i.e. the `http_user` and `http_pass` spider attributes) for Splash authentication will have any non-Splash request expose your credentials to the request target. This includes `robots.txt` requests sent by Scrapy when the `ROBOTSTXT_OBEY` setting is set to `True`. Upgrade to scrapy-splash 0.8.0 and use the new `SPLASH_USER` and `SPLASH_PASS` settings instead to set your Splash authentication credentials safely. If you cannot upgrade, set your Splash request credentials on a per-request basis, [using the `splash_headers` request parameter](https://github.com/scrapy-plugins/scrapy-splash/tree/0.8.x#http-basic-auth), instead of defining them globally using the [`HttpAuthMiddleware`](http://doc.scrapy.org/en/latest/topics/downloader-middleware.html#module-scrapy.downloadermiddlewares.httpauth). Alternatively, make sure all your requests go through Splash. That includes disabling the [robots.txt middleware](https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#topics-dlmw-robots).",
    "cve_publish_date": "2021-10-05",
    "cwe_id": "CWE-200",
    "cwe_name": "Exposure of Sensitive Information to an Unauthorized Actor",
    "cwe_description": "The product exposes sensitive information to an actor that is not explicitly authorized to have access to that information.",
    "commit_message": "Implement SPLASH_USER and SPLASH_PASS",
    "type_of_change": "Modification",
    "filename_of_changes": "utils.py",
    "code_language": "Python",
    "number_of_lines_added_for_mitigation": "12",
    "number_of_lines_deleted_vulnerable_to_cve": "21",
    "vulnerable_lines": [
        "// Line_Reference 6: from twisted.web.resource import Resource",
        "// Line_Reference 9: from scrapy_splash.utils import to_bytes",
        "// Line_Reference 10: from tests.mockserver import MockServer",
        "// Line_Reference 19: class HtmlResource(Resource):",
        "// Line_Reference 20:     isLeaf = True",
        "// Line_Reference 21:     content_type = 'text/html'",
        "// Line_Reference 22:     html = ''",
        "// Line_Reference 23:     extra_headers = {}",
        "// Line_Reference 24:     status_code = 200",
        "// Line_Reference 25: ",
        "// Line_Reference 26:     def render_GET(self, request):",
        "// Line_Reference 27:         request.setHeader(b'content-type', to_bytes(self.content_type))",
        "// Line_Reference 28:         for name, value in self.extra_headers.items():",
        "// Line_Reference 29:             request.setHeader(to_bytes(name), to_bytes(value))",
        "// Line_Reference 30:         request.setResponseCode(self.status_code)",
        "// Line_Reference 31:         return to_bytes(self.html)",
        "// Line_Reference 32: ",
        "// Line_Reference 33: ",
        "// Line_Reference 35: def crawl_items(spider_cls, resource_cls, settings, spider_kwargs=None):",
        "// Line_Reference 43:         root_url = s.root_url",
        "// Line_Reference 45:     result = crawler.spider.collected_items, s.root_url, crawler"
    ]
}
