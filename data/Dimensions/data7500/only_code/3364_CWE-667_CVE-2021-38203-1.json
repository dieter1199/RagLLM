struct btrfs_transaction *cur_trans = trans->transaction;
again:
u64 reserved = atomic64_read(&cur_trans->chunk_bytes_reserved);
/*
* If there's not available space for the chunk tree (system
* space) and there are other tasks that reserved space for
* creating a new system block group, wait for them to complete
* the creation of their system block group and release excess
* reserved space. We do this because:
*
* *) We can end up allocating more system chunks than necessary
*    when there are multiple tasks that are concurrently
*    allocating block groups, which can lead to exhaustion of
*    the system array in the superblock;
*
* *) If we allocate extra and unnecessary system block groups,
*    despite being empty for a long time, and possibly forever,
*    they end not being added to the list of unused block groups
*    because that typically happens only when deallocating the
*    last extent from a block group - which never happens since
*    we never allocate from them in the first place. The few
*    exceptions are when mounting a filesystem or running scrub,
*    which add unused block groups to the list of unused block
*    groups, to be deleted by the cleaner kthread.
*    And even when they are added to the list of unused block
*    groups, it can take a long time until they get deleted,
*    since the cleaner kthread might be sleeping or busy with
*    other work (deleting subvolumes, running delayed iputs,
*    defrag scheduling, etc);
*
* This is rare in practice, but can happen when too many tasks
* are allocating blocks groups in parallel (via fallocate())
* and before the one that reserved space for a new system block
* group finishes the block group creation and releases the space
* reserved in excess (at btrfs_create_pending_block_groups()),
* other tasks end up here and see free system space temporarily
* not enough for updating the chunk tree.
*
* We unlock the chunk mutex before waiting for such tasks and
* lock it again after the wait, otherwise we would deadlock.
* It is safe to do so because allocating a system chunk is the
* first thing done while allocating a new block group.
*/
if (reserved > trans->chunk_bytes_reserved) {
const u64 min_needed = reserved - thresh;
mutex_unlock(&fs_info->chunk_mutex);
wait_event(cur_trans->chunk_reserve_wait,
atomic64_read(&cur_trans->chunk_bytes_reserved) <=
min_needed);
mutex_lock(&fs_info->chunk_mutex);
goto again;
}
if (!ret) {
atomic64_add(thresh, &cur_trans->chunk_bytes_reserved);
}
