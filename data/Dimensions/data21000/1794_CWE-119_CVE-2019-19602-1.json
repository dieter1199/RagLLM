{
    "cve_id": "CVE-2019-19602",
    "cve_description": "fpregs_state_valid in arch/x86/include/asm/fpu/internal.h in the Linux kernel before 5.4.2, when GCC 9 is used, allows context-dependent attackers to cause a denial of service (memory corruption) or possibly have unspecified other impact because of incorrect fpu_fpregs_owner_ctx caching, as demonstrated by mishandling of signal-based non-cooperative preemption in Go 1.14 prereleases on amd64, aka CID-59c4bd853abc.",
    "cve_publish_date": "2019-12-05",
    "cwe_id": "CWE-119",
    "cwe_name": "Improper Restriction of Operations within the Bounds of a Memory Buffer",
    "cwe_description": "The product performs operations on a memory buffer, but it reads from or writes to a memory location outside the buffer's intended boundary. This may result in read or write operations on unexpected memory locations that could be linked to other variables, data structures, or internal program data.",
    "commit_message": "x86/fpu: Don't cache access to fpu_fpregs_owner_ctx\n\nThe state/owner of the FPU is saved to fpu_fpregs_owner_ctx by pointing\nto the context that is currently loaded. It never changed during the\nlifetime of a task - it remained stable/constant.\n\nAfter deferred FPU registers loading until return to userland was\nimplemented, the content of fpu_fpregs_owner_ctx may change during\npreemption and must not be cached.\n\nThis went unnoticed for some time and was now noticed, in particular\nsince gcc 9 is caching that load in copy_fpstate_to_sigframe() and\nreusing it in the retry loop:\n\n  copy_fpstate_to_sigframe()\n    load fpu_fpregs_owner_ctx and save on stack\n    fpregs_lock()\n    copy_fpregs_to_sigframe() /* failed */\n    fpregs_unlock()\n         *** PREEMPTION, another uses FPU, changes fpu_fpregs_owner_ctx ***\n\n    fault_in_pages_writeable() /* succeed, retry */\n\n    fpregs_lock()\n\t__fpregs_load_activate()\n\t  fpregs_state_valid() /* uses fpu_fpregs_owner_ctx from stack */\n    copy_fpregs_to_sigframe() /* succeeds, random FPU content */\n\nThis is a comparison of the assembly produced by gcc 9, without vs with this\npatch:\n\n| # arch/x86/kernel/fpu/signal.c:173:      if (!access_ok(buf, size))\n|        cmpq    %rdx, %rax      # tmp183, _4\n|        jb      .L190   #,\n|-# arch/x86/include/asm/fpu/internal.h:512:       return fpu == this_cpu_read_stable(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n|-#APP\n|-# 512 \"arch/x86/include/asm/fpu/internal.h\" 1\n|-       movq %gs:fpu_fpregs_owner_ctx,%rax      #, pfo_ret__\n|-# 0 \"\" 2\n|-#NO_APP\n|-       movq    %rax, -88(%rbp) # pfo_ret__, %sfp\nâ€¦\n|-# arch/x86/include/asm/fpu/internal.h:512:       return fpu == this_cpu_read_stable(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n|-       movq    -88(%rbp), %rcx # %sfp, pfo_ret__\n|-       cmpq    %rcx, -64(%rbp) # pfo_ret__, %sfp\n|+# arch/x86/include/asm/fpu/internal.h:512:       return fpu == this_cpu_read(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n|+#APP\n|+# 512 \"arch/x86/include/asm/fpu/internal.h\" 1\n|+       movq %gs:fpu_fpregs_owner_ctx(%rip),%rax        # fpu_fpregs_owner_ctx, pfo_ret__\n|+# 0 \"\" 2\n|+# arch/x86/include/asm/fpu/internal.h:512:       return fpu == this_cpu_read(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;\n|+#NO_APP\n|+       cmpq    %rax, -64(%rbp) # pfo_ret__, %sfp\n\nUse this_cpu_read() instead this_cpu_read_stable() to avoid caching of\nfpu_fpregs_owner_ctx during preemption points.\n\nThe Fixes: tag points to the commit where deferred FPU loading was\nadded. Since this commit, the compiler is no longer allowed to move the\nload of fpu_fpregs_owner_ctx somewhere else / outside of the locked\nsection. A task preemption will change its value and stale content will\nbe observed.\n\n [ bp: Massage. ]\n\nDebugged-by: Austin Clements <austin@google.com>\nDebugged-by: David Chase <drchase@golang.org>\nDebugged-by: Ian Lance Taylor <ian@airs.com>\nFixes: 5f409e20b7945 (\"x86/fpu: Defer FPU state load until return to userspace\")\nSigned-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>\nSigned-off-by: Borislav Petkov <bp@suse.de>\nReviewed-by: Rik van Riel <riel@surriel.com>\nTested-by: Borislav Petkov <bp@suse.de>\nCc: Aubrey Li <aubrey.li@intel.com>\nCc: Austin Clements <austin@google.com>\nCc: Barret Rhoden <brho@google.com>\nCc: Dave Hansen <dave.hansen@intel.com>\nCc: David Chase <drchase@golang.org>\nCc: \"H. Peter Anvin\" <hpa@zytor.com>\nCc: ian@airs.com\nCc: Ingo Molnar <mingo@redhat.com>\nCc: Josh Bleecher Snyder <josharian@gmail.com>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: x86-ml <x86@kernel.org>\nLink: https://lkml.kernel.org/r/20191128085306.hxfa2o3knqtu4wfn@linutronix.de\nLink: https://bugzilla.kernel.org/show_bug.cgi?id=205663",
    "type_of_change": "Modification",
    "filename_of_changes": "internal.h",
    "code_language": "C",
    "number_of_lines_added_for_mitigation": "1",
    "number_of_lines_deleted_vulnerable_to_cve": "1",
    "vulnerable_lines": [
        "// Line_Reference 512: \treturn fpu == this_cpu_read_stable(fpu_fpregs_owner_ctx) && cpu == fpu->last_cpu;"
    ]
}
