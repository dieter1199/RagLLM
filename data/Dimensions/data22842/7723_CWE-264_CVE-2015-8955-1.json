{
    "cve_id": "CVE-2015-8955",
    "cve_description": "arch/arm64/kernel/perf_event.c in the Linux kernel before 4.1 on arm64 platforms allows local users to gain privileges or cause a denial of service (invalid pointer dereference) via vectors involving events that are mishandled during a span of multiple HW PMUs.",
    "cve_publish_date": "2016-10-10",
    "cwe_id": "CWE-264",
    "cwe_name": "Permissions, Privileges, and Access Controls",
    "cwe_description": "Weaknesses in this category are related to the management of permissions, privileges, and other security features that are used to perform access control.",
    "commit_message": "arm64: perf: reject groups spanning multiple HW PMUs\n\nThe perf core implicitly rejects events spanning multiple HW PMUs, as in\nthese cases the event->ctx will differ. However this validation is\nperformed after pmu::event_init() is called in perf_init_event(), and\nthus pmu::event_init() may be called with a group leader from a\ndifferent HW PMU.\n\nThe ARM64 PMU driver does not take this fact into account, and when\nvalidating groups assumes that it can call to_arm_pmu(event->pmu) for\nany HW event. When the event in question is from another HW PMU this is\nwrong, and results in dereferencing garbage.\n\nThis patch updates the ARM64 PMU driver to first test for and reject\nevents from other PMUs, moving the to_arm_pmu and related logic after\nthis test. Fixes a crash triggered by perf_fuzzer on Linux-4.0-rc2, with\na CCI PMU present:\n\nBad mode in Synchronous Abort handler detected, code 0x86000006 -- IABT (current EL)\nCPU: 0 PID: 1371 Comm: perf_fuzzer Not tainted 3.19.0+ #249\nHardware name: V2F-1XV7 Cortex-A53x2 SMM (DT)\ntask: ffffffc07c73a280 ti: ffffffc07b0a0000 task.ti: ffffffc07b0a0000\nPC is at 0x0\nLR is at validate_event+0x90/0xa8\npc : [<0000000000000000>] lr : [<ffffffc000090228>] pstate: 00000145\nsp : ffffffc07b0a3ba0\n\n[<          (null)>]           (null)\n[<ffffffc0000907d8>] armpmu_event_init+0x174/0x3cc\n[<ffffffc00015d870>] perf_try_init_event+0x34/0x70\n[<ffffffc000164094>] perf_init_event+0xe0/0x10c\n[<ffffffc000164348>] perf_event_alloc+0x288/0x358\n[<ffffffc000164c5c>] SyS_perf_event_open+0x464/0x98c\nCode: bad PC value\n\nAlso cleans up the code to use the arm_pmu only when we know\nthat we are dealing with an arm pmu event.\n\nCc: Will Deacon <will.deacon@arm.com>\nAcked-by: Mark Rutland <mark.rutland@arm.com>\nAcked-by: Peter Ziljstra (Intel) <peterz@infradead.org>\nSigned-off-by: Suzuki K. Poulose <suzuki.poulose@arm.com>\nSigned-off-by: Will Deacon <will.deacon@arm.com>",
    "type_of_change": "Modification",
    "filename_of_changes": "perf_event.c",
    "code_language": "C",
    "number_of_lines_added_for_mitigation": "15",
    "number_of_lines_deleted_vulnerable_to_cve": "6",
    "vulnerable_lines": [
        "// Line_Reference 325: validate_event(struct pmu_hw_events *hw_events,",
        "// Line_Reference 326: \t       struct perf_event *event)",
        "// Line_Reference 328: \tstruct arm_pmu *armpmu = to_arm_pmu(event->pmu);",
        "// Line_Reference 358: \tif (!validate_event(&fake_pmu, leader))",
        "// Line_Reference 362: \t\tif (!validate_event(&fake_pmu, sibling))",
        "// Line_Reference 366: \tif (!validate_event(&fake_pmu, event))"
    ]
}
