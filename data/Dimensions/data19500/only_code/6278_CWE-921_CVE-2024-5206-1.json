expected_stop_words = {
"celeri",
"tomato",
"copyright",
"coke",
"sparkling",
"water",
"the",
}
assert vectorizer.stop_words_ == expected_stop_words
assert len(vect.stop_words_) == 0
assert "a" in vect.stop_words_
assert len(vect.stop_words_) == 2
assert "a" in vect.stop_words_
assert len(vect.stop_words_) == 2
assert len(vect.stop_words_) == 0
assert "c" in vect.stop_words_
assert len(vect.stop_words_) == 4
assert "c" in vect.stop_words_
assert len(vect.stop_words_) == 5
def test_stop_words_removal():
# Ensure that deleting the stop_words_ attribute doesn't affect transform
fitted_vectorizers = (
TfidfVectorizer().fit(JUNK_FOOD_DOCS),
CountVectorizer(preprocessor=strip_tags).fit(JUNK_FOOD_DOCS),
CountVectorizer(strip_accents=strip_eacute).fit(JUNK_FOOD_DOCS),
)
for vect in fitted_vectorizers:
vect_transform = vect.transform(JUNK_FOOD_DOCS).toarray()
vect.stop_words_ = None
stop_None_transform = vect.transform(JUNK_FOOD_DOCS).toarray()
delattr(vect, "stop_words_")
stop_del_transform = vect.transform(JUNK_FOOD_DOCS).toarray()
assert_array_equal(stop_None_transform, vect_transform)
assert_array_equal(stop_del_transform, vect_transform)
