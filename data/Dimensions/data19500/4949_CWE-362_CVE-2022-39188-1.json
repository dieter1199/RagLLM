{
    "cve_id": "CVE-2022-39188",
    "cve_description": "An issue was discovered in include/asm-generic/tlb.h in the Linux kernel before 5.19. Because of a race condition (unmap_mapping_range versus munmap), a device driver can free a page while it still has stale TLB entries. This only occurs in situations with VM_PFNMAP VMAs.",
    "cve_publish_date": "2022-09-02",
    "cwe_id": "CWE-362",
    "cwe_name": "Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition')",
    "cwe_description": "The product contains a code sequence that can run concurrently with other code, and the code sequence requires temporary, exclusive access to a shared resource, but a timing window exists in which the shared resource can be modified by another code sequence that is operating concurrently.",
    "commit_message": "mmu_gather: Force tlb-flush VM_PFNMAP vmas\n\nJann reported a race between munmap() and unmap_mapping_range(), where\nunmap_mapping_range() will no-op once unmap_vmas() has unlinked the\nVMA; however munmap() will not yet have invalidated the TLBs.\n\nTherefore unmap_mapping_range() will complete while there are still\n(stale) TLB entries for the specified range.\n\nMitigate this by force flushing TLBs for VM_PFNMAP ranges.\n\nSigned-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>\nAcked-by: Will Deacon <will@kernel.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
    "type_of_change": "Modification",
    "filename_of_changes": "tlb.h",
    "code_language": "C",
    "number_of_lines_added_for_mitigation": "17",
    "number_of_lines_deleted_vulnerable_to_cve": "16",
    "vulnerable_lines": [
        "// Line_Reference 376: ",
        "// Line_Reference 415: #else",
        "// Line_Reference 416: ",
        "// Line_Reference 417: static inline void",
        "// Line_Reference 418: tlb_update_vma_flags(struct mmu_gather *tlb, struct vm_area_struct *vma) { }",
        "// Line_Reference 419: ",
        "// Line_Reference 420: #endif",
        "// Line_Reference 421: ",
        "// Line_Reference 422: #endif /* CONFIG_MMU_GATHER_NO_RANGE */",
        "// Line_Reference 423: ",
        "// Line_Reference 510: \tif (tlb->fullmm || IS_ENABLED(CONFIG_MMU_GATHER_MERGE_VMAS))",
        "// Line_Reference 514: \t * Do a TLB flush and reset the range at VMA boundaries; this avoids",
        "// Line_Reference 515: \t * the ranges growing with the unused space between consecutive VMAs,",
        "// Line_Reference 516: \t * but also the mmu_gather::vma_* flags from tlb_start_vma() rely on",
        "// Line_Reference 517: \t * this.",
        "// Line_Reference 519: \ttlb_flush_mmu_tlbonly(tlb);"
    ]
}
